import unittest

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import pickle as pickle
import sys

from CARTGV import CARTGVTree, CARTGVTreeBuilder
from CARTGV import CARTGVSplitter, BaseDenseCARTGVSplitter, BestCARTGVSplitter
from CARTGV import CARTGVCriterion, CARTGVClassificationCriterion, CARTGVGini

from sklearn.utils.validation import check_random_state
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.tree import plot_tree
from sklearn.tree._tree import DepthFirstTreeBuilder, BestFirstTreeBuilder, Tree
from sklearn.tree._splitter import BestSplitter
from sklearn.tree._criterion import Gini, Entropy

from scipy.sparse import issparse
from numpy import float32 as DTYPE
from numpy import float64 as DOUBLE


# tree = CARTGVTree(n_grouped_features, n_classes, n_outputs)

# builder = CARTGVTreeBuilder(splitter, min_samples_split,
#                             min_samples_leaf, min_weight_leaf,
#                             max_depth, mgroup, mvar,
#                             min_impurity_decrease, min_impurity_split)

class CARTGVCriterionTest(unittest.TestCase):

    def test_cinit_CARTGVClassificationCriterion_v2(self):

        # df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)
        #
        # train = df.loc[df['Type'] == 'train']
        #
        # y = train['Y']

        y = np.array([[0], [1], [0], [1], [1]])

        y = np.atleast_1d(y)

        if y.ndim == 1:
            y = np.reshape(y, (-1, 1))

        n_outputs = y.shape[1]

        y = np.copy(y)

        classes = []
        n_classes = []

        y_encoded = np.zeros(y.shape, dtype=np.float64)
        for k in range(n_outputs):
            classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
            classes.append(classes_k)
            n_classes.append(classes_k.shape[0])

        y = y_encoded

        n_classes = np.array(n_classes, dtype=np.intp)

        criterion = CARTGVClassificationCriterion(n_outputs, n_classes)

        self.assertIsNone(criterion.sample_weight)
        self.assertIsNone(criterion.samples)
        self.assertIsNone(criterion.starts)
        self.assertIsNone(criterion.ends)
        self.assertIsNone(criterion.impurity_childs)
        self.assertEqual(criterion.n_childs, 0)
        self.assertEqual(criterion.n_outputs, n_outputs)
        self.assertEqual(criterion.n_samples, 0)
        self.assertEqual(criterion.n_node_samples, 0)
        self.assertEqual(criterion.weighted_n_node_samples, 0.0)
        self.assertIsNone(criterion.weighted_n_childs)
        # self.assertIsNone(criterion.sum_childs) # Property a faire
        self.assertSequenceEqual(criterion.n_classes.tolist(), n_classes.tolist())
        self.assertEqual(criterion.sum_stride, max(n_classes))
        self.assertSequenceEqual(criterion.sum_total.tolist(), np.zeros(n_outputs*criterion.sum_stride).tolist())

    def test_proxy_impurity_improvement_CARTGVClassificationCriterion_v2(self):
        df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)

        train = df.loc[df['Type'] == 'train']

        X = train.iloc[:, 2:]

        y = train['Y']

        # X = np.array([[-0.962564615251298, -0.0818379297761482, -0.257129359665299, -1.20057124658537,
        #                -1.67321037673198, -0.850857878613548, -1.12636943482486, 0.264691871869928, 0.823490524418768,
        #                -0.289267055667413, 0.375612134943435, 0.689033636785644, -0.0755870733096488,
        #                -0.253686040025422, -0.767686310824219, -0.47706960213735, 0.619681515116366, -0.718706304417254,
        #                -0.625998377401577, 0.595352830214443, -0.826055466109155, 0.841770278364141, 0.525998122722698,
        #                -0.305537695526707, -0.551540574269715],
        #               [-0.0170226173861495, -0.575187308059669, -0.0550716676440694, -0.596082039595892,
        #                -0.153767849941737, -0.152659395126548, 0.103284766044348, 0.945962098961183, 0.11395628892521,
        #                -1.0314335555107, -0.24180964927081, -0.225116148572662, 1.75090409682049, 0.276212128428595,
        #                -0.226985192750251, -0.688321496802469, 0.721869146316049, -0.0427129520106458, 1.71093452174155,
        #                0.440414655312213, -0.219061974136534, 0.370516601227188, -0.579953711046926, -2.4756697600574,
        #                -2.09969534371281],
        #               [0.859846852829686, -0.196768997920202, -0.665097766775893, 1.49845086392502, 0.712519776986412,
        #                0.63382801135412, 0.338132006534241, -1.17912479597116, 0.337710921150664, -0.404533729530606,
        #                0.984579714687047, -1.16236566382262, -0.786198019602607, -0.753822112046281, -0.811264249392465,
        #                -0.594151853267325, -0.322916128201519, -1.2934117213506, 0.531732629482942, -1.6136606736686,
        #                -1.27887838930757, 0.678437793765498, -1.19080597429513, 1.11533360829611, -0.340409112584892],
        #               [-1.46244895844162, 0.508777691805245, -0.42599215315616, -0.570342024814983, -1.13004768682085,
        #                1.12406519881936, 0.251809560422478, -2.06632443310484, -1.23862336004496, 1.6527814698557,
        #                0.336827946772908, -0.233201791535758, 0.590072797080428, 1.7453946472635, 1.02016573606479,
        #                -0.813457453508146, -0.0745696971758758, 2.89463767013771, 0.158622453385045, -1.70880561223817,
        #                0.132671092412739, -0.479946273307748, 0.11444508132886, 1.40287375218729, -0.344499428025485],
        #               [-0.383681631574503, 1.19713456197882, -0.302078922002226, -0.544313316070517, 1.11301409047452,
        #                0.0643648126207925, 0.623795834834719, 0.288528481567621, -0.618352387217919, -0.180420032776369,
        #                -0.974252399377197, -0.78154085269986, 0.673878430962106, -0.14493184535421, -1.58840476437875,
        #                -0.89040398934659, -0.464336091106138, -0.804400496705168, 0.542582301058101, -0.213424538311193,
        #                -0.925675256270349, 0.306707969484467, 0.378645850648093, 0.220134583700443, -0.0925601673405935]
        #               ], dtype=np.float32)
        #
        # y = np.array([[0], [1], [0], [1], [1]])

        y = np.atleast_1d(y)

        if y.ndim == 1:
            y = np.reshape(y, (-1, 1))

        n_outputs = y.shape[1]

        y = np.copy(y)

        classes = []
        n_classes = []

        y_encoded = np.zeros(y.shape, dtype=np.float64)
        for k in range(n_outputs):
            classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
            classes.append(classes_k)
            n_classes.append(classes_k.shape[0])

        y = y_encoded

        n_classes = np.array(n_classes, dtype=np.intp)

        criterion = CARTGVGini(n_outputs, n_classes)

        sample_weight = None
        weighted_n_samples = X.shape[0]
        samples = np.arange(X.shape[0], dtype=np.intp)
        start = np.intp(0)
        end = np.intp(X.shape[0] - 1)
        criterion.test_init(y, sample_weight, weighted_n_samples, samples, start, end)
        criterion.test_reset()
        criterion.test_update()
        improvement = criterion.test_proxy_impurity_improvement()

        self.assertTrue(improvement <= 0)

    def test_impurity_improvement_CARTGVClassificationCriterion_v2(self):
        df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)

        train = df.loc[df['Type'] == 'train']

        X = train.iloc[:, 2:]

        y = train['Y']

        # X = np.array([[-0.962564615251298, -0.0818379297761482, -0.257129359665299, -1.20057124658537,
        #                -1.67321037673198, -0.850857878613548, -1.12636943482486, 0.264691871869928, 0.823490524418768,
        #                -0.289267055667413, 0.375612134943435, 0.689033636785644, -0.0755870733096488,
        #                -0.253686040025422, -0.767686310824219, -0.47706960213735, 0.619681515116366, -0.718706304417254,
        #                -0.625998377401577, 0.595352830214443, -0.826055466109155, 0.841770278364141, 0.525998122722698,
        #                -0.305537695526707, -0.551540574269715],
        #               [-0.0170226173861495, -0.575187308059669, -0.0550716676440694, -0.596082039595892,
        #                -0.153767849941737, -0.152659395126548, 0.103284766044348, 0.945962098961183, 0.11395628892521,
        #                -1.0314335555107, -0.24180964927081, -0.225116148572662, 1.75090409682049, 0.276212128428595,
        #                -0.226985192750251, -0.688321496802469, 0.721869146316049, -0.0427129520106458, 1.71093452174155,
        #                0.440414655312213, -0.219061974136534, 0.370516601227188, -0.579953711046926, -2.4756697600574,
        #                -2.09969534371281],
        #               [0.859846852829686, -0.196768997920202, -0.665097766775893, 1.49845086392502, 0.712519776986412,
        #                0.63382801135412, 0.338132006534241, -1.17912479597116, 0.337710921150664, -0.404533729530606,
        #                0.984579714687047, -1.16236566382262, -0.786198019602607, -0.753822112046281, -0.811264249392465,
        #                -0.594151853267325, -0.322916128201519, -1.2934117213506, 0.531732629482942, -1.6136606736686,
        #                -1.27887838930757, 0.678437793765498, -1.19080597429513, 1.11533360829611, -0.340409112584892],
        #               [-1.46244895844162, 0.508777691805245, -0.42599215315616, -0.570342024814983, -1.13004768682085,
        #                1.12406519881936, 0.251809560422478, -2.06632443310484, -1.23862336004496, 1.6527814698557,
        #                0.336827946772908, -0.233201791535758, 0.590072797080428, 1.7453946472635, 1.02016573606479,
        #                -0.813457453508146, -0.0745696971758758, 2.89463767013771, 0.158622453385045, -1.70880561223817,
        #                0.132671092412739, -0.479946273307748, 0.11444508132886, 1.40287375218729, -0.344499428025485],
        #               [-0.383681631574503, 1.19713456197882, -0.302078922002226, -0.544313316070517, 1.11301409047452,
        #                0.0643648126207925, 0.623795834834719, 0.288528481567621, -0.618352387217919, -0.180420032776369,
        #                -0.974252399377197, -0.78154085269986, 0.673878430962106, -0.14493184535421, -1.58840476437875,
        #                -0.89040398934659, -0.464336091106138, -0.804400496705168, 0.542582301058101, -0.213424538311193,
        #                -0.925675256270349, 0.306707969484467, 0.378645850648093, 0.220134583700443, -0.0925601673405935]
        #               ], dtype=np.float32)
        #
        # y = np.array([[0], [1], [0], [1], [1]])

        y = np.atleast_1d(y)

        if y.ndim == 1:
            y = np.reshape(y, (-1, 1))

        n_outputs = y.shape[1]

        y = np.copy(y)

        classes = []
        n_classes = []

        y_encoded = np.zeros(y.shape, dtype=np.float64)
        for k in range(n_outputs):
            classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
            classes.append(classes_k)
            n_classes.append(classes_k.shape[0])

        y = y_encoded

        n_classes = np.array(n_classes, dtype=np.intp)

        criterion = CARTGVGini(n_outputs, n_classes)

        sample_weight = None
        weighted_n_samples = X.shape[0]
        samples = np.arange(X.shape[0], dtype=np.intp)
        start = np.intp(0)
        end = np.intp(X.shape[0] - 1)
        criterion.test_init(y, sample_weight, weighted_n_samples, samples, start, end)
        criterion.test_reset()
        criterion.test_update()
        impurity_parent = criterion.test_node_impurity()
        improvement = criterion.test_impurity_improvement(impurity_parent,np.array(criterion.test_children_impurity()))
        print(improvement)
        # self.assertTrue(improvement >= 0)

    def test_init_CARTGVClassificationCriterion_v2(self):
        # df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)
        #
        # train = df.loc[df['Type'] == 'train']
        #
        # X = train.iloc[:, 2:]
        #
        # y = train['Y']
        #
        # g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
        # g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
        # g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
        # g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
        # g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]
        #
        # groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])

        X = np.array([[-0.962564615251298, -0.0818379297761482, -0.257129359665299, -1.20057124658537,
                       -1.67321037673198, -0.850857878613548, -1.12636943482486, 0.264691871869928, 0.823490524418768,
                       -0.289267055667413, 0.375612134943435, 0.689033636785644, -0.0755870733096488,
                       -0.253686040025422, -0.767686310824219, -0.47706960213735, 0.619681515116366, -0.718706304417254,
                       -0.625998377401577, 0.595352830214443, -0.826055466109155, 0.841770278364141, 0.525998122722698,
                       -0.305537695526707, -0.551540574269715],
                      [-0.0170226173861495, -0.575187308059669, -0.0550716676440694, -0.596082039595892,
                       -0.153767849941737, -0.152659395126548, 0.103284766044348, 0.945962098961183, 0.11395628892521,
                       -1.0314335555107, -0.24180964927081, -0.225116148572662, 1.75090409682049, 0.276212128428595,
                       -0.226985192750251, -0.688321496802469, 0.721869146316049, -0.0427129520106458, 1.71093452174155,
                       0.440414655312213, -0.219061974136534, 0.370516601227188, -0.579953711046926, -2.4756697600574,
                       -2.09969534371281],
                      [0.859846852829686, -0.196768997920202, -0.665097766775893, 1.49845086392502, 0.712519776986412,
                       0.63382801135412, 0.338132006534241, -1.17912479597116, 0.337710921150664, -0.404533729530606,
                       0.984579714687047, -1.16236566382262, -0.786198019602607, -0.753822112046281, -0.811264249392465,
                       -0.594151853267325, -0.322916128201519, -1.2934117213506, 0.531732629482942, -1.6136606736686,
                       -1.27887838930757, 0.678437793765498, -1.19080597429513, 1.11533360829611, -0.340409112584892],
                      [-1.46244895844162, 0.508777691805245, -0.42599215315616, -0.570342024814983, -1.13004768682085,
                       1.12406519881936, 0.251809560422478, -2.06632443310484, -1.23862336004496, 1.6527814698557,
                       0.336827946772908, -0.233201791535758, 0.590072797080428, 1.7453946472635, 1.02016573606479,
                       -0.813457453508146, -0.0745696971758758, 2.89463767013771, 0.158622453385045, -1.70880561223817,
                       0.132671092412739, -0.479946273307748, 0.11444508132886, 1.40287375218729, -0.344499428025485],
                      [-0.383681631574503, 1.19713456197882, -0.302078922002226, -0.544313316070517, 1.11301409047452,
                       0.0643648126207925, 0.623795834834719, 0.288528481567621, -0.618352387217919, -0.180420032776369,
                       -0.974252399377197, -0.78154085269986, 0.673878430962106, -0.14493184535421, -1.58840476437875,
                       -0.89040398934659, -0.464336091106138, -0.804400496705168, 0.542582301058101, -0.213424538311193,
                       -0.925675256270349, 0.306707969484467, 0.378645850648093, 0.220134583700443, -0.0925601673405935]
                      ], dtype=np.float32)

        y = np.array([[0], [1], [0], [1], [1]])

        y = np.atleast_1d(y)

        if y.ndim == 1:
            y = np.reshape(y, (-1, 1))

        n_outputs = y.shape[1]

        y = np.copy(y)

        classes = []
        n_classes = []

        y_encoded = np.zeros(y.shape, dtype=np.float64)
        for k in range(n_outputs):
            classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
            classes.append(classes_k)
            n_classes.append(classes_k.shape[0])

        y = y_encoded

        n_classes = np.array(n_classes, dtype=np.intp)

        criterion = CARTGVClassificationCriterion(n_outputs, n_classes)

        sample_weight = None
        weighted_n_samples = X.shape[0]
        samples = np.arange(X.shape[0], dtype=np.intp)
        start = np.intp(0)
        end = np.intp(X.shape[0])
        criterion.test_init(y, sample_weight, weighted_n_samples, samples, start, end)

        self.assertEqual(np.array(criterion.y).all(), y.all())
        self.assertEqual(criterion.sample_weight, sample_weight)
        # self.assertSequenceEqual(criterion.starts.tolist(), [start])
        # self.assertSequenceEqual(criterion.ends.tolist(), [end])
        self.assertEqual(criterion.n_node_samples, end - start)
        self.assertEqual(criterion.weighted_n_samples, weighted_n_samples)
        self.assertEqual(criterion.weighted_n_node_samples, np.sum(np.ones(X.shape[0])))

    def test_reset_CARTGVClassificationCriterion_v2(self):
        # df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)
        #
        # train = df.loc[df['Type'] == 'train']
        #
        # X = train.iloc[:, 2:]
        #
        # y = train['Y']
        #
        # g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
        # g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
        # g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
        # g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
        # g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]
        #
        # groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])

        X = np.array([[-0.962564615251298, -0.0818379297761482, -0.257129359665299, -1.20057124658537,
                       -1.67321037673198, -0.850857878613548, -1.12636943482486, 0.264691871869928, 0.823490524418768,
                       -0.289267055667413, 0.375612134943435, 0.689033636785644, -0.0755870733096488,
                       -0.253686040025422, -0.767686310824219, -0.47706960213735, 0.619681515116366, -0.718706304417254,
                       -0.625998377401577, 0.595352830214443, -0.826055466109155, 0.841770278364141, 0.525998122722698,
                       -0.305537695526707, -0.551540574269715],
                      [-0.0170226173861495, -0.575187308059669, -0.0550716676440694, -0.596082039595892,
                       -0.153767849941737, -0.152659395126548, 0.103284766044348, 0.945962098961183, 0.11395628892521,
                       -1.0314335555107, -0.24180964927081, -0.225116148572662, 1.75090409682049, 0.276212128428595,
                       -0.226985192750251, -0.688321496802469, 0.721869146316049, -0.0427129520106458, 1.71093452174155,
                       0.440414655312213, -0.219061974136534, 0.370516601227188, -0.579953711046926, -2.4756697600574,
                       -2.09969534371281],
                      [0.859846852829686, -0.196768997920202, -0.665097766775893, 1.49845086392502, 0.712519776986412,
                       0.63382801135412, 0.338132006534241, -1.17912479597116, 0.337710921150664, -0.404533729530606,
                       0.984579714687047, -1.16236566382262, -0.786198019602607, -0.753822112046281, -0.811264249392465,
                       -0.594151853267325, -0.322916128201519, -1.2934117213506, 0.531732629482942, -1.6136606736686,
                       -1.27887838930757, 0.678437793765498, -1.19080597429513, 1.11533360829611, -0.340409112584892],
                      [-1.46244895844162, 0.508777691805245, -0.42599215315616, -0.570342024814983, -1.13004768682085,
                       1.12406519881936, 0.251809560422478, -2.06632443310484, -1.23862336004496, 1.6527814698557,
                       0.336827946772908, -0.233201791535758, 0.590072797080428, 1.7453946472635, 1.02016573606479,
                       -0.813457453508146, -0.0745696971758758, 2.89463767013771, 0.158622453385045, -1.70880561223817,
                       0.132671092412739, -0.479946273307748, 0.11444508132886, 1.40287375218729, -0.344499428025485],
                      [-0.383681631574503, 1.19713456197882, -0.302078922002226, -0.544313316070517, 1.11301409047452,
                       0.0643648126207925, 0.623795834834719, 0.288528481567621, -0.618352387217919, -0.180420032776369,
                       -0.974252399377197, -0.78154085269986, 0.673878430962106, -0.14493184535421, -1.58840476437875,
                       -0.89040398934659, -0.464336091106138, -0.804400496705168, 0.542582301058101, -0.213424538311193,
                       -0.925675256270349, 0.306707969484467, 0.378645850648093, 0.220134583700443, -0.0925601673405935]
                      ], dtype=np.float32)

        y = np.array([[0], [1], [0], [1], [1]])

        y = np.atleast_1d(y)

        if y.ndim == 1:
            y = np.reshape(y, (-1, 1))

        n_outputs = y.shape[1]

        y = np.copy(y)

        classes = []
        n_classes = []

        y_encoded = np.zeros(y.shape, dtype=np.float64)
        for k in range(n_outputs):
            classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
            classes.append(classes_k)
            n_classes.append(classes_k.shape[0])

        y = y_encoded

        n_classes = np.array(n_classes, dtype=np.intp)

        criterion = CARTGVClassificationCriterion(n_outputs, n_classes)

        sample_weight = None
        weighted_n_samples = X.shape[0]
        samples = np.arange(X.shape[0], dtype=np.intp)
        start = np.intp(0)
        end = np.intp(X.shape[0] - 1)
        criterion.test_init(y, sample_weight, weighted_n_samples, samples, start, end)
        criterion.test_reset()

    def test_update_CARTGVClassificationCriterion_v2(self):
        df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)

        train = df.loc[df['Type'] == 'train']

        X = train.iloc[:, 2:]

        y = train['Y']

        # X = np.array([[-0.962564615251298, -0.0818379297761482, -0.257129359665299, -1.20057124658537,
        #                -1.67321037673198, -0.850857878613548, -1.12636943482486, 0.264691871869928, 0.823490524418768,
        #                -0.289267055667413, 0.375612134943435, 0.689033636785644, -0.0755870733096488,
        #                -0.253686040025422, -0.767686310824219, -0.47706960213735, 0.619681515116366, -0.718706304417254,
        #                -0.625998377401577, 0.595352830214443, -0.826055466109155, 0.841770278364141, 0.525998122722698,
        #                -0.305537695526707, -0.551540574269715],
        #               [-0.0170226173861495, -0.575187308059669, -0.0550716676440694, -0.596082039595892,
        #                -0.153767849941737, -0.152659395126548, 0.103284766044348, 0.945962098961183, 0.11395628892521,
        #                -1.0314335555107, -0.24180964927081, -0.225116148572662, 1.75090409682049, 0.276212128428595,
        #                -0.226985192750251, -0.688321496802469, 0.721869146316049, -0.0427129520106458, 1.71093452174155,
        #                0.440414655312213, -0.219061974136534, 0.370516601227188, -0.579953711046926, -2.4756697600574,
        #                -2.09969534371281],
        #               [0.859846852829686, -0.196768997920202, -0.665097766775893, 1.49845086392502, 0.712519776986412,
        #                0.63382801135412, 0.338132006534241, -1.17912479597116, 0.337710921150664, -0.404533729530606,
        #                0.984579714687047, -1.16236566382262, -0.786198019602607, -0.753822112046281, -0.811264249392465,
        #                -0.594151853267325, -0.322916128201519, -1.2934117213506, 0.531732629482942, -1.6136606736686,
        #                -1.27887838930757, 0.678437793765498, -1.19080597429513, 1.11533360829611, -0.340409112584892],
        #               [-1.46244895844162, 0.508777691805245, -0.42599215315616, -0.570342024814983, -1.13004768682085,
        #                1.12406519881936, 0.251809560422478, -2.06632443310484, -1.23862336004496, 1.6527814698557,
        #                0.336827946772908, -0.233201791535758, 0.590072797080428, 1.7453946472635, 1.02016573606479,
        #                -0.813457453508146, -0.0745696971758758, 2.89463767013771, 0.158622453385045, -1.70880561223817,
        #                0.132671092412739, -0.479946273307748, 0.11444508132886, 1.40287375218729, -0.344499428025485],
        #               [-0.383681631574503, 1.19713456197882, -0.302078922002226, -0.544313316070517, 1.11301409047452,
        #                0.0643648126207925, 0.623795834834719, 0.288528481567621, -0.618352387217919, -0.180420032776369,
        #                -0.974252399377197, -0.78154085269986, 0.673878430962106, -0.14493184535421, -1.58840476437875,
        #                -0.89040398934659, -0.464336091106138, -0.804400496705168, 0.542582301058101, -0.213424538311193,
        #                -0.925675256270349, 0.306707969484467, 0.378645850648093, 0.220134583700443, -0.0925601673405935]
        #               ], dtype=np.float32)
        #
        # y = np.array([[0], [1], [0], [1], [1]])

        y = np.atleast_1d(y)

        if y.ndim == 1:
            y = np.reshape(y, (-1, 1))

        n_outputs = y.shape[1]

        y = np.copy(y)

        classes = []
        n_classes = []

        y_encoded = np.zeros(y.shape, dtype=np.float64)
        for k in range(n_outputs):
            classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
            classes.append(classes_k)
            n_classes.append(classes_k.shape[0])

        y = y_encoded

        n_classes = np.array(n_classes, dtype=np.intp)

        criterion = CARTGVClassificationCriterion(n_outputs, n_classes)

        sample_weight = None
        weighted_n_samples = X.shape[0]
        samples = np.arange(X.shape[0], dtype=np.intp)
        start = np.intp(0)
        end = np.intp(X.shape[0] - 1)
        criterion.test_init(y, sample_weight, weighted_n_samples, samples, start, end)
        criterion.test_reset()
        criterion.test_update()

    def test_node_value_CARTGVClassificationCriterion_v2(self):
        df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)

        train = df.loc[df['Type'] == 'train']

        X = train.iloc[:, 2:]

        y = train['Y']

        # X = np.array([[-0.962564615251298, -0.0818379297761482, -0.257129359665299, -1.20057124658537,
        #                -1.67321037673198, -0.850857878613548, -1.12636943482486, 0.264691871869928, 0.823490524418768,
        #                -0.289267055667413, 0.375612134943435, 0.689033636785644, -0.0755870733096488,
        #                -0.253686040025422, -0.767686310824219, -0.47706960213735, 0.619681515116366, -0.718706304417254,
        #                -0.625998377401577, 0.595352830214443, -0.826055466109155, 0.841770278364141, 0.525998122722698,
        #                -0.305537695526707, -0.551540574269715],
        #               [-0.0170226173861495, -0.575187308059669, -0.0550716676440694, -0.596082039595892,
        #                -0.153767849941737, -0.152659395126548, 0.103284766044348, 0.945962098961183, 0.11395628892521,
        #                -1.0314335555107, -0.24180964927081, -0.225116148572662, 1.75090409682049, 0.276212128428595,
        #                -0.226985192750251, -0.688321496802469, 0.721869146316049, -0.0427129520106458, 1.71093452174155,
        #                0.440414655312213, -0.219061974136534, 0.370516601227188, -0.579953711046926, -2.4756697600574,
        #                -2.09969534371281],
        #               [0.859846852829686, -0.196768997920202, -0.665097766775893, 1.49845086392502, 0.712519776986412,
        #                0.63382801135412, 0.338132006534241, -1.17912479597116, 0.337710921150664, -0.404533729530606,
        #                0.984579714687047, -1.16236566382262, -0.786198019602607, -0.753822112046281, -0.811264249392465,
        #                -0.594151853267325, -0.322916128201519, -1.2934117213506, 0.531732629482942, -1.6136606736686,
        #                -1.27887838930757, 0.678437793765498, -1.19080597429513, 1.11533360829611, -0.340409112584892],
        #               [-1.46244895844162, 0.508777691805245, -0.42599215315616, -0.570342024814983, -1.13004768682085,
        #                1.12406519881936, 0.251809560422478, -2.06632443310484, -1.23862336004496, 1.6527814698557,
        #                0.336827946772908, -0.233201791535758, 0.590072797080428, 1.7453946472635, 1.02016573606479,
        #                -0.813457453508146, -0.0745696971758758, 2.89463767013771, 0.158622453385045, -1.70880561223817,
        #                0.132671092412739, -0.479946273307748, 0.11444508132886, 1.40287375218729, -0.344499428025485],
        #               [-0.383681631574503, 1.19713456197882, -0.302078922002226, -0.544313316070517, 1.11301409047452,
        #                0.0643648126207925, 0.623795834834719, 0.288528481567621, -0.618352387217919, -0.180420032776369,
        #                -0.974252399377197, -0.78154085269986, 0.673878430962106, -0.14493184535421, -1.58840476437875,
        #                -0.89040398934659, -0.464336091106138, -0.804400496705168, 0.542582301058101, -0.213424538311193,
        #                -0.925675256270349, 0.306707969484467, 0.378645850648093, 0.220134583700443, -0.0925601673405935]
        #               ], dtype=np.float32)
        #
        # y = np.array([[0], [1], [0], [1], [1]])

        y = np.atleast_1d(y)

        if y.ndim == 1:
            y = np.reshape(y, (-1, 1))

        n_outputs = y.shape[1]

        y = np.copy(y)

        classes = []
        n_classes = []

        y_encoded = np.zeros(y.shape, dtype=np.float64)
        for k in range(n_outputs):
            classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
            classes.append(classes_k)
            n_classes.append(classes_k.shape[0])

        y = y_encoded

        n_classes = np.array(n_classes, dtype=np.intp)

        criterion = CARTGVClassificationCriterion(n_outputs, n_classes)

        sample_weight = None
        weighted_n_samples = X.shape[0]
        samples = np.arange(X.shape[0], dtype=np.intp)
        start = np.intp(0)
        end = np.intp(X.shape[0] - 1)
        criterion.test_init(y, sample_weight, weighted_n_samples, samples, start, end)
        criterion.test_reset()
        criterion.test_node_value()

    def test_node_impurity_CARTGVGini_v2(self):
        df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)

        train = df.loc[df['Type'] == 'train']

        X = train.iloc[:, 2:]

        y = train['Y']

        # X = np.array([[-0.962564615251298, -0.0818379297761482, -0.257129359665299, -1.20057124658537,
        #                -1.67321037673198, -0.850857878613548, -1.12636943482486, 0.264691871869928, 0.823490524418768,
        #                -0.289267055667413, 0.375612134943435, 0.689033636785644, -0.0755870733096488,
        #                -0.253686040025422, -0.767686310824219, -0.47706960213735, 0.619681515116366, -0.718706304417254,
        #                -0.625998377401577, 0.595352830214443, -0.826055466109155, 0.841770278364141, 0.525998122722698,
        #                -0.305537695526707, -0.551540574269715],
        #               [-0.0170226173861495, -0.575187308059669, -0.0550716676440694, -0.596082039595892,
        #                -0.153767849941737, -0.152659395126548, 0.103284766044348, 0.945962098961183, 0.11395628892521,
        #                -1.0314335555107, -0.24180964927081, -0.225116148572662, 1.75090409682049, 0.276212128428595,
        #                -0.226985192750251, -0.688321496802469, 0.721869146316049, -0.0427129520106458, 1.71093452174155,
        #                0.440414655312213, -0.219061974136534, 0.370516601227188, -0.579953711046926, -2.4756697600574,
        #                -2.09969534371281],
        #               [0.859846852829686, -0.196768997920202, -0.665097766775893, 1.49845086392502, 0.712519776986412,
        #                0.63382801135412, 0.338132006534241, -1.17912479597116, 0.337710921150664, -0.404533729530606,
        #                0.984579714687047, -1.16236566382262, -0.786198019602607, -0.753822112046281, -0.811264249392465,
        #                -0.594151853267325, -0.322916128201519, -1.2934117213506, 0.531732629482942, -1.6136606736686,
        #                -1.27887838930757, 0.678437793765498, -1.19080597429513, 1.11533360829611, -0.340409112584892],
        #               [-1.46244895844162, 0.508777691805245, -0.42599215315616, -0.570342024814983, -1.13004768682085,
        #                1.12406519881936, 0.251809560422478, -2.06632443310484, -1.23862336004496, 1.6527814698557,
        #                0.336827946772908, -0.233201791535758, 0.590072797080428, 1.7453946472635, 1.02016573606479,
        #                -0.813457453508146, -0.0745696971758758, 2.89463767013771, 0.158622453385045, -1.70880561223817,
        #                0.132671092412739, -0.479946273307748, 0.11444508132886, 1.40287375218729, -0.344499428025485],
        #               [-0.383681631574503, 1.19713456197882, -0.302078922002226, -0.544313316070517, 1.11301409047452,
        #                0.0643648126207925, 0.623795834834719, 0.288528481567621, -0.618352387217919, -0.180420032776369,
        #                -0.974252399377197, -0.78154085269986, 0.673878430962106, -0.14493184535421, -1.58840476437875,
        #                -0.89040398934659, -0.464336091106138, -0.804400496705168, 0.542582301058101, -0.213424538311193,
        #                -0.925675256270349, 0.306707969484467, 0.378645850648093, 0.220134583700443, -0.0925601673405935]
        #               ], dtype=np.float32)
        #
        # y = np.array([[0], [1], [0], [1], [1]])

        y = np.atleast_1d(y)

        if y.ndim == 1:
            y = np.reshape(y, (-1, 1))

        n_outputs = y.shape[1]

        y = np.copy(y)

        classes = []
        n_classes = []

        y_encoded = np.zeros(y.shape, dtype=np.float64)
        for k in range(n_outputs):
            classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
            classes.append(classes_k)
            n_classes.append(classes_k.shape[0])

        y = y_encoded

        n_classes = np.array(n_classes, dtype=np.intp)

        criterion = CARTGVGini(n_outputs, n_classes)

        sample_weight = None
        weighted_n_samples = X.shape[0]
        samples = np.arange(X.shape[0], dtype=np.intp)
        start = np.intp(0)
        end = np.intp(X.shape[0] - 1)
        criterion.test_init(y, sample_weight, weighted_n_samples, samples, start, end)
        criterion.test_reset()
        criterion.test_update()
        impurity = criterion.test_node_impurity()

        self.assertTrue(impurity >= 0)

    def test_children_impurity_CARTGVGini_v2(self):
        df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)

        train = df.loc[df['Type'] == 'train']

        X = train.iloc[:, 2:]

        y = train['Y']

        # X = np.array([[-0.962564615251298, -0.0818379297761482, -0.257129359665299, -1.20057124658537,
        #                -1.67321037673198, -0.850857878613548, -1.12636943482486, 0.264691871869928, 0.823490524418768,
        #                -0.289267055667413, 0.375612134943435, 0.689033636785644, -0.0755870733096488,
        #                -0.253686040025422, -0.767686310824219, -0.47706960213735, 0.619681515116366, -0.718706304417254,
        #                -0.625998377401577, 0.595352830214443, -0.826055466109155, 0.841770278364141, 0.525998122722698,
        #                -0.305537695526707, -0.551540574269715],
        #               [-0.0170226173861495, -0.575187308059669, -0.0550716676440694, -0.596082039595892,
        #                -0.153767849941737, -0.152659395126548, 0.103284766044348, 0.945962098961183, 0.11395628892521,
        #                -1.0314335555107, -0.24180964927081, -0.225116148572662, 1.75090409682049, 0.276212128428595,
        #                -0.226985192750251, -0.688321496802469, 0.721869146316049, -0.0427129520106458, 1.71093452174155,
        #                0.440414655312213, -0.219061974136534, 0.370516601227188, -0.579953711046926, -2.4756697600574,
        #                -2.09969534371281],
        #               [0.859846852829686, -0.196768997920202, -0.665097766775893, 1.49845086392502, 0.712519776986412,
        #                0.63382801135412, 0.338132006534241, -1.17912479597116, 0.337710921150664, -0.404533729530606,
        #                0.984579714687047, -1.16236566382262, -0.786198019602607, -0.753822112046281, -0.811264249392465,
        #                -0.594151853267325, -0.322916128201519, -1.2934117213506, 0.531732629482942, -1.6136606736686,
        #                -1.27887838930757, 0.678437793765498, -1.19080597429513, 1.11533360829611, -0.340409112584892],
        #               [-1.46244895844162, 0.508777691805245, -0.42599215315616, -0.570342024814983, -1.13004768682085,
        #                1.12406519881936, 0.251809560422478, -2.06632443310484, -1.23862336004496, 1.6527814698557,
        #                0.336827946772908, -0.233201791535758, 0.590072797080428, 1.7453946472635, 1.02016573606479,
        #                -0.813457453508146, -0.0745696971758758, 2.89463767013771, 0.158622453385045, -1.70880561223817,
        #                0.132671092412739, -0.479946273307748, 0.11444508132886, 1.40287375218729, -0.344499428025485],
        #               [-0.383681631574503, 1.19713456197882, -0.302078922002226, -0.544313316070517, 1.11301409047452,
        #                0.0643648126207925, 0.623795834834719, 0.288528481567621, -0.618352387217919, -0.180420032776369,
        #                -0.974252399377197, -0.78154085269986, 0.673878430962106, -0.14493184535421, -1.58840476437875,
        #                -0.89040398934659, -0.464336091106138, -0.804400496705168, 0.542582301058101, -0.213424538311193,
        #                -0.925675256270349, 0.306707969484467, 0.378645850648093, 0.220134583700443, -0.0925601673405935]
        #               ], dtype=np.float32)
        #
        # y = np.array([[0], [1], [0], [1], [1]])

        y = np.atleast_1d(y)

        if y.ndim == 1:
            y = np.reshape(y, (-1, 1))

        n_outputs = y.shape[1]

        y = np.copy(y)

        classes = []
        n_classes = []

        y_encoded = np.zeros(y.shape, dtype=np.float64)
        for k in range(n_outputs):
            classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
            classes.append(classes_k)
            n_classes.append(classes_k.shape[0])

        y = y_encoded

        n_classes = np.array(n_classes, dtype=np.intp)

        criterion = CARTGVGini(n_outputs, n_classes)

        sample_weight = None
        weighted_n_samples = X.shape[0]
        samples = np.arange(X.shape[0], dtype=np.intp)
        start = np.intp(0)
        end = np.intp(X.shape[0] - 1)
        criterion.test_init(y, sample_weight, weighted_n_samples, samples, start, end)
        criterion.test_reset()
        criterion.test_update()
        criterion.test_children_impurity()


class CARTGVSplitterTest(unittest.TestCase):

    def test_cinit_splitter_v2(self):

        # df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)
        #
        # train = df.loc[df['Type'] == 'train']
        #
        # X = train.iloc[:, 2:]
        #
        # y = train['Y']
        #
        # g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
        # g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
        # g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
        # g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
        # g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]
        #
        # groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])

        X = np.array([[-0.962564615251298, -0.0818379297761482, -0.257129359665299, -1.20057124658537,
                       -1.67321037673198, -0.850857878613548, -1.12636943482486, 0.264691871869928, 0.823490524418768,
                       -0.289267055667413, 0.375612134943435, 0.689033636785644, -0.0755870733096488,
                       -0.253686040025422, -0.767686310824219, -0.47706960213735, 0.619681515116366, -0.718706304417254,
                       -0.625998377401577, 0.595352830214443, -0.826055466109155, 0.841770278364141, 0.525998122722698,
                       -0.305537695526707, -0.551540574269715],
                      [-0.0170226173861495, -0.575187308059669, -0.0550716676440694, -0.596082039595892,
                       -0.153767849941737, -0.152659395126548, 0.103284766044348, 0.945962098961183, 0.11395628892521,
                       -1.0314335555107, -0.24180964927081, -0.225116148572662, 1.75090409682049, 0.276212128428595,
                       -0.226985192750251, -0.688321496802469, 0.721869146316049, -0.0427129520106458, 1.71093452174155,
                       0.440414655312213, -0.219061974136534, 0.370516601227188, -0.579953711046926, -2.4756697600574,
                       -2.09969534371281],
                      [0.859846852829686, -0.196768997920202, -0.665097766775893, 1.49845086392502, 0.712519776986412,
                       0.63382801135412, 0.338132006534241, -1.17912479597116, 0.337710921150664, -0.404533729530606,
                       0.984579714687047, -1.16236566382262, -0.786198019602607, -0.753822112046281, -0.811264249392465,
                       -0.594151853267325, -0.322916128201519, -1.2934117213506, 0.531732629482942, -1.6136606736686,
                       -1.27887838930757, 0.678437793765498, -1.19080597429513, 1.11533360829611, -0.340409112584892],
                      [-1.46244895844162, 0.508777691805245, -0.42599215315616, -0.570342024814983, -1.13004768682085,
                       1.12406519881936, 0.251809560422478, -2.06632443310484, -1.23862336004496, 1.6527814698557,
                       0.336827946772908, -0.233201791535758, 0.590072797080428, 1.7453946472635, 1.02016573606479,
                       -0.813457453508146, -0.0745696971758758, 2.89463767013771, 0.158622453385045, -1.70880561223817,
                       0.132671092412739, -0.479946273307748, 0.11444508132886, 1.40287375218729, -0.344499428025485],
                      [-0.383681631574503, 1.19713456197882, -0.302078922002226, -0.544313316070517, 1.11301409047452,
                       0.0643648126207925, 0.623795834834719, 0.288528481567621, -0.618352387217919, -0.180420032776369,
                       -0.974252399377197, -0.78154085269986, 0.673878430962106, -0.14493184535421, -1.58840476437875,
                       -0.89040398934659, -0.464336091106138, -0.804400496705168, 0.542582301058101, -0.213424538311193,
                       -0.925675256270349, 0.306707969484467, 0.378645850648093, 0.220134583700443, -0.0925601673405935]
                      ], dtype=np.float32)

        y = np.array([[0], [1], [0], [1], [1]])

        groups = np.array(
            [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19], [20, 21, 22, 23, 24]])

        y = np.atleast_1d(y)
        max_grouped_features = max([len(groups[i]) for i in range(len(groups))])
        min_samples_leaf = 1
        min_weight_leaf = 0
        random_state = check_random_state(2457)


        if y.ndim == 1:
            y = np.reshape(y, (-1, 1))

        n_outputs = y.shape[1]

        y = np.copy(y)

        classes = []
        n_classes = []

        y_encoded = np.zeros(y.shape, dtype=np.float64)
        for k in range(n_outputs):
            classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
            classes.append(classes_k)
            n_classes.append(classes_k.shape[0])

        y = y_encoded

        n_classes = np.array(n_classes, dtype=np.intp)

        criterion = CARTGVGini(n_outputs, n_classes)

        splitter = CARTGVSplitter(criterion, max_grouped_features, len(groups),
                                     min_samples_leaf, min_weight_leaf,
                                     random_state)

        self.assertEqual(type(splitter.criterion),type(criterion))
        self.assertIsNone(splitter.samples)
        self.assertEqual(splitter.n_samples,0)
        self.assertIsNone(splitter.features)
        self.assertEqual(splitter.n_features,0)
        self.assertIsNone(splitter.sample_weight)
        self.assertEqual(splitter.max_grouped_features,max_grouped_features)
        self.assertEqual(splitter.min_weight_leaf,min_weight_leaf)
        self.assertEqual(splitter.min_samples_leaf,min_samples_leaf)
        self.assertEqual(splitter.random_state,random_state)
        self.assertEqual(np.array(splitter.groups).all(),np.empty((len(groups), max_grouped_features), dtype=int).all())
        self.assertEqual(splitter.n_groups,len(groups))
        self.assertEqual(np.array(splitter.len_groups).all(),np.empty((len(groups)), dtype=int).all())
        self.assertIsNone(splitter.splitting_tree_builder)
        self.assertIsNone(splitter.splitting_tree)

    def test_init_splitter_v2(self):

        # df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)
        #
        # train = df.loc[df['Type'] == 'train']
        #
        # X = train.iloc[:, 2:]
        #
        # y = train['Y']
        #
        # g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
        # g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
        # g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
        # g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
        # g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]
        #
        # groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])

        X = np.array([[-0.962564615251298, -0.0818379297761482, -0.257129359665299, -1.20057124658537,
                       -1.67321037673198, -0.850857878613548, -1.12636943482486, 0.264691871869928, 0.823490524418768,
                       -0.289267055667413, 0.375612134943435, 0.689033636785644, -0.0755870733096488,
                       -0.253686040025422, -0.767686310824219, -0.47706960213735, 0.619681515116366, -0.718706304417254,
                       -0.625998377401577, 0.595352830214443, -0.826055466109155, 0.841770278364141, 0.525998122722698,
                       -0.305537695526707, -0.551540574269715],
                      [-0.0170226173861495, -0.575187308059669, -0.0550716676440694, -0.596082039595892,
                       -0.153767849941737, -0.152659395126548, 0.103284766044348, 0.945962098961183, 0.11395628892521,
                       -1.0314335555107, -0.24180964927081, -0.225116148572662, 1.75090409682049, 0.276212128428595,
                       -0.226985192750251, -0.688321496802469, 0.721869146316049, -0.0427129520106458, 1.71093452174155,
                       0.440414655312213, -0.219061974136534, 0.370516601227188, -0.579953711046926, -2.4756697600574,
                       -2.09969534371281],
                      [0.859846852829686, -0.196768997920202, -0.665097766775893, 1.49845086392502, 0.712519776986412,
                       0.63382801135412, 0.338132006534241, -1.17912479597116, 0.337710921150664, -0.404533729530606,
                       0.984579714687047, -1.16236566382262, -0.786198019602607, -0.753822112046281, -0.811264249392465,
                       -0.594151853267325, -0.322916128201519, -1.2934117213506, 0.531732629482942, -1.6136606736686,
                       -1.27887838930757, 0.678437793765498, -1.19080597429513, 1.11533360829611, -0.340409112584892],
                      [-1.46244895844162, 0.508777691805245, -0.42599215315616, -0.570342024814983, -1.13004768682085,
                       1.12406519881936, 0.251809560422478, -2.06632443310484, -1.23862336004496, 1.6527814698557,
                       0.336827946772908, -0.233201791535758, 0.590072797080428, 1.7453946472635, 1.02016573606479,
                       -0.813457453508146, -0.0745696971758758, 2.89463767013771, 0.158622453385045, -1.70880561223817,
                       0.132671092412739, -0.479946273307748, 0.11444508132886, 1.40287375218729, -0.344499428025485],
                      [-0.383681631574503, 1.19713456197882, -0.302078922002226, -0.544313316070517, 1.11301409047452,
                       0.0643648126207925, 0.623795834834719, 0.288528481567621, -0.618352387217919, -0.180420032776369,
                       -0.974252399377197, -0.78154085269986, 0.673878430962106, -0.14493184535421, -1.58840476437875,
                       -0.89040398934659, -0.464336091106138, -0.804400496705168, 0.542582301058101, -0.213424538311193,
                       -0.925675256270349, 0.306707969484467, 0.378645850648093, 0.220134583700443, -0.0925601673405935]
                      ], dtype=np.float32)

        y = np.array([[0], [1], [0], [1], [1]])

        groups = np.array(
            [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19], [20, 21, 22, 23, 24]])

        y = np.atleast_1d(y)
        max_grouped_features = max([len(groups[i]) for i in range(len(groups))])
        min_samples_leaf = 1
        min_weight_leaf = 0
        random_state = np.random.RandomState(2547)

        if y.ndim == 1:
            y = np.reshape(y, (-1, 1))

        n_outputs = y.shape[1]

        y = np.copy(y)

        classes = []
        n_classes = []

        y_encoded = np.zeros(y.shape, dtype=np.float64)
        for k in range(n_outputs):
            classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
            classes.append(classes_k)
            n_classes.append(classes_k.shape[0])

        y = y_encoded

        n_classes = np.array(n_classes, dtype=np.intp)

        criterion = CARTGVGini(n_outputs, n_classes)

        splitter = CARTGVSplitter(criterion, max_grouped_features, len(groups),
                                     min_samples_leaf, min_weight_leaf,
                                     random_state)

        sample_weight = None
        res = splitter.test_init(X, y, sample_weight, groups)

        self.assertEqual(res, 0)
        # self.assertTrue(np.array(splitter.samples).all() == np.arange(X.shape[0]).all())
        self.assertEqual(splitter.n_samples,X.shape[0])
        self.assertEqual(splitter.weighted_n_samples,X.shape[0])
        # self.assertTrue((splitter.features).all() == np.arange(X.shape[1]).all())
        self.assertEqual(splitter.n_features,X.shape[1]) # Est ce que c'est vraiment cela que l'on veut ???
        # self.assertTrue(y.all() == np.asarray(splitter.y).all())
        # if sample_weight != None:
            # self.assertTrue(np.asarray(splitter.sample_weight).all() == sample_weight.all())
        # self.assertTrue(np.array(splitter.groups).all() == groups.all())
        self.assertEqual(splitter.n_groups, len(groups))
        # self.assertTrue(np.array(splitter.len_groups).all() == np.array([len(group) for group in groups]).all())

    def test_node_reset_splitter_v2(self):

        # df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)
        #
        # train = df.loc[df['Type'] == 'train']
        #
        # X = train.iloc[:, 2:]
        #
        # y = train['Y']
        #
        # g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
        # g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
        # g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
        # g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
        # g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]
        #
        # groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])

        X = np.array([[-0.962564615251298, -0.0818379297761482, -0.257129359665299, -1.20057124658537,
                       -1.67321037673198, -0.850857878613548, -1.12636943482486, 0.264691871869928, 0.823490524418768,
                       -0.289267055667413, 0.375612134943435, 0.689033636785644, -0.0755870733096488,
                       -0.253686040025422, -0.767686310824219, -0.47706960213735, 0.619681515116366, -0.718706304417254,
                       -0.625998377401577, 0.595352830214443, -0.826055466109155, 0.841770278364141, 0.525998122722698,
                       -0.305537695526707, -0.551540574269715],
                      [-0.0170226173861495, -0.575187308059669, -0.0550716676440694, -0.596082039595892,
                       -0.153767849941737, -0.152659395126548, 0.103284766044348, 0.945962098961183, 0.11395628892521,
                       -1.0314335555107, -0.24180964927081, -0.225116148572662, 1.75090409682049, 0.276212128428595,
                       -0.226985192750251, -0.688321496802469, 0.721869146316049, -0.0427129520106458, 1.71093452174155,
                       0.440414655312213, -0.219061974136534, 0.370516601227188, -0.579953711046926, -2.4756697600574,
                       -2.09969534371281],
                      [0.859846852829686, -0.196768997920202, -0.665097766775893, 1.49845086392502, 0.712519776986412,
                       0.63382801135412, 0.338132006534241, -1.17912479597116, 0.337710921150664, -0.404533729530606,
                       0.984579714687047, -1.16236566382262, -0.786198019602607, -0.753822112046281, -0.811264249392465,
                       -0.594151853267325, -0.322916128201519, -1.2934117213506, 0.531732629482942, -1.6136606736686,
                       -1.27887838930757, 0.678437793765498, -1.19080597429513, 1.11533360829611, -0.340409112584892],
                      [-1.46244895844162, 0.508777691805245, -0.42599215315616, -0.570342024814983, -1.13004768682085,
                       1.12406519881936, 0.251809560422478, -2.06632443310484, -1.23862336004496, 1.6527814698557,
                       0.336827946772908, -0.233201791535758, 0.590072797080428, 1.7453946472635, 1.02016573606479,
                       -0.813457453508146, -0.0745696971758758, 2.89463767013771, 0.158622453385045, -1.70880561223817,
                       0.132671092412739, -0.479946273307748, 0.11444508132886, 1.40287375218729, -0.344499428025485],
                      [-0.383681631574503, 1.19713456197882, -0.302078922002226, -0.544313316070517, 1.11301409047452,
                       0.0643648126207925, 0.623795834834719, 0.288528481567621, -0.618352387217919, -0.180420032776369,
                       -0.974252399377197, -0.78154085269986, 0.673878430962106, -0.14493184535421, -1.58840476437875,
                       -0.89040398934659, -0.464336091106138, -0.804400496705168, 0.542582301058101, -0.213424538311193,
                       -0.925675256270349, 0.306707969484467, 0.378645850648093, 0.220134583700443, -0.0925601673405935]
                      ], dtype=np.float32)

        y = np.array([[0], [1], [0], [1], [1]])

        groups = np.array(
            [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19], [20, 21, 22, 23, 24]])

        n_samples, n_features = X.shape
        y = np.atleast_1d(y)
        max_grouped_features = max([len(groups[i]) for i in range(len(groups))])
        min_samples_leaf = 1
        min_weight_leaf = 0
        random_state = check_random_state(2457)

        if y.ndim == 1:
            y = np.reshape(y, (-1, 1))

        n_outputs = y.shape[1]

        y = np.copy(y)

        classes = []
        n_classes = []

        y_encoded = np.zeros(y.shape, dtype=np.float64)
        for k in range(n_outputs):
            classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
            classes.append(classes_k)
            n_classes.append(classes_k.shape[0])

        y = y_encoded

        n_classes = np.array(n_classes, dtype=np.intp)

        criterion = CARTGVGini(n_outputs, n_classes)

        splitter = CARTGVSplitter(criterion, max_grouped_features, len(groups),
                                     min_samples_leaf, min_weight_leaf,
                                     random_state)

        sample_weight = None
        splitter.test_init(X, y, sample_weight, groups)

        start = 0
        end = n_samples
        weighted_n_node_samples = 0
        res = splitter.test_node_reset(start, end, weighted_n_node_samples)

        self.assertEqual(res,0)
        self.assertEqual(splitter.start,start)
        self.assertEqual(splitter.end,end)

    def test_node_value_splitter_v2(self):

        # df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)
        #
        # train = df.loc[df['Type'] == 'train']
        #
        # X = train.iloc[:, 2:]
        #
        # y = train['Y']
        #
        # g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
        # g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
        # g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
        # g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
        # g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]
        #
        # groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])

        X = np.array([[-0.962564615251298, -0.0818379297761482, -0.257129359665299, -1.20057124658537,
                       -1.67321037673198, -0.850857878613548, -1.12636943482486, 0.264691871869928, 0.823490524418768,
                       -0.289267055667413, 0.375612134943435, 0.689033636785644, -0.0755870733096488,
                       -0.253686040025422, -0.767686310824219, -0.47706960213735, 0.619681515116366, -0.718706304417254,
                       -0.625998377401577, 0.595352830214443, -0.826055466109155, 0.841770278364141, 0.525998122722698,
                       -0.305537695526707, -0.551540574269715],
                      [-0.0170226173861495, -0.575187308059669, -0.0550716676440694, -0.596082039595892,
                       -0.153767849941737, -0.152659395126548, 0.103284766044348, 0.945962098961183, 0.11395628892521,
                       -1.0314335555107, -0.24180964927081, -0.225116148572662, 1.75090409682049, 0.276212128428595,
                       -0.226985192750251, -0.688321496802469, 0.721869146316049, -0.0427129520106458, 1.71093452174155,
                       0.440414655312213, -0.219061974136534, 0.370516601227188, -0.579953711046926, -2.4756697600574,
                       -2.09969534371281],
                      [0.859846852829686, -0.196768997920202, -0.665097766775893, 1.49845086392502, 0.712519776986412,
                       0.63382801135412, 0.338132006534241, -1.17912479597116, 0.337710921150664, -0.404533729530606,
                       0.984579714687047, -1.16236566382262, -0.786198019602607, -0.753822112046281, -0.811264249392465,
                       -0.594151853267325, -0.322916128201519, -1.2934117213506, 0.531732629482942, -1.6136606736686,
                       -1.27887838930757, 0.678437793765498, -1.19080597429513, 1.11533360829611, -0.340409112584892],
                      [-1.46244895844162, 0.508777691805245, -0.42599215315616, -0.570342024814983, -1.13004768682085,
                       1.12406519881936, 0.251809560422478, -2.06632443310484, -1.23862336004496, 1.6527814698557,
                       0.336827946772908, -0.233201791535758, 0.590072797080428, 1.7453946472635, 1.02016573606479,
                       -0.813457453508146, -0.0745696971758758, 2.89463767013771, 0.158622453385045, -1.70880561223817,
                       0.132671092412739, -0.479946273307748, 0.11444508132886, 1.40287375218729, -0.344499428025485],
                      [-0.383681631574503, 1.19713456197882, -0.302078922002226, -0.544313316070517, 1.11301409047452,
                       0.0643648126207925, 0.623795834834719, 0.288528481567621, -0.618352387217919, -0.180420032776369,
                       -0.974252399377197, -0.78154085269986, 0.673878430962106, -0.14493184535421, -1.58840476437875,
                       -0.89040398934659, -0.464336091106138, -0.804400496705168, 0.542582301058101, -0.213424538311193,
                       -0.925675256270349, 0.306707969484467, 0.378645850648093, 0.220134583700443, -0.0925601673405935]
                      ], dtype=np.float32)

        y = np.array([[0], [1], [0], [1], [1]])

        groups = np.array(
            [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19], [20, 21, 22, 23, 24]])

        n_samples, n_features = X.shape
        y = np.atleast_1d(y)
        max_grouped_features = max([len(groups[i]) for i in range(len(groups))])
        min_samples_leaf = 1
        min_weight_leaf = 0
        random_state = check_random_state(2457)

        if y.ndim == 1:
            y = np.reshape(y, (-1, 1))

        n_outputs = y.shape[1]

        y = np.copy(y)

        classes = []
        n_classes = []

        y_encoded = np.zeros(y.shape, dtype=np.float64)
        for k in range(n_outputs):
            classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
            classes.append(classes_k)
            n_classes.append(classes_k.shape[0])

        y = y_encoded

        n_classes = np.array(n_classes, dtype=np.intp)

        criterion = CARTGVGini(n_outputs, n_classes)

        splitter = CARTGVSplitter(criterion, max_grouped_features, len(groups),
                                     min_samples_leaf, min_weight_leaf,
                                     random_state)

        sample_weight = None
        splitter.test_init(X, y, sample_weight, groups)

        start = 0
        end = n_samples
        weighted_n_node_samples = 0
        splitter.test_node_reset(start, end, weighted_n_node_samples)

        node_value = splitter.test_node_value(0)
        self.assertTrue(node_value >= 0)

    def test_node_impurity_splitter_v2(self):

        # df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)
        #
        # train = df.loc[df['Type'] == 'train']
        #
        # X = train.iloc[:, 2:]
        #
        # y = train['Y']
        #
        # g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
        # g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
        # g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
        # g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
        # g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]
        #
        # groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])

        X = np.array([[-0.962564615251298, -0.0818379297761482, -0.257129359665299, -1.20057124658537,
                       -1.67321037673198, -0.850857878613548, -1.12636943482486, 0.264691871869928, 0.823490524418768,
                       -0.289267055667413, 0.375612134943435, 0.689033636785644, -0.0755870733096488,
                       -0.253686040025422, -0.767686310824219, -0.47706960213735, 0.619681515116366, -0.718706304417254,
                       -0.625998377401577, 0.595352830214443, -0.826055466109155, 0.841770278364141, 0.525998122722698,
                       -0.305537695526707, -0.551540574269715],
                      [-0.0170226173861495, -0.575187308059669, -0.0550716676440694, -0.596082039595892,
                       -0.153767849941737, -0.152659395126548, 0.103284766044348, 0.945962098961183, 0.11395628892521,
                       -1.0314335555107, -0.24180964927081, -0.225116148572662, 1.75090409682049, 0.276212128428595,
                       -0.226985192750251, -0.688321496802469, 0.721869146316049, -0.0427129520106458, 1.71093452174155,
                       0.440414655312213, -0.219061974136534, 0.370516601227188, -0.579953711046926, -2.4756697600574,
                       -2.09969534371281],
                      [0.859846852829686, -0.196768997920202, -0.665097766775893, 1.49845086392502, 0.712519776986412,
                       0.63382801135412, 0.338132006534241, -1.17912479597116, 0.337710921150664, -0.404533729530606,
                       0.984579714687047, -1.16236566382262, -0.786198019602607, -0.753822112046281, -0.811264249392465,
                       -0.594151853267325, -0.322916128201519, -1.2934117213506, 0.531732629482942, -1.6136606736686,
                       -1.27887838930757, 0.678437793765498, -1.19080597429513, 1.11533360829611, -0.340409112584892],
                      [-1.46244895844162, 0.508777691805245, -0.42599215315616, -0.570342024814983, -1.13004768682085,
                       1.12406519881936, 0.251809560422478, -2.06632443310484, -1.23862336004496, 1.6527814698557,
                       0.336827946772908, -0.233201791535758, 0.590072797080428, 1.7453946472635, 1.02016573606479,
                       -0.813457453508146, -0.0745696971758758, 2.89463767013771, 0.158622453385045, -1.70880561223817,
                       0.132671092412739, -0.479946273307748, 0.11444508132886, 1.40287375218729, -0.344499428025485],
                      [-0.383681631574503, 1.19713456197882, -0.302078922002226, -0.544313316070517, 1.11301409047452,
                       0.0643648126207925, 0.623795834834719, 0.288528481567621, -0.618352387217919, -0.180420032776369,
                       -0.974252399377197, -0.78154085269986, 0.673878430962106, -0.14493184535421, -1.58840476437875,
                       -0.89040398934659, -0.464336091106138, -0.804400496705168, 0.542582301058101, -0.213424538311193,
                       -0.925675256270349, 0.306707969484467, 0.378645850648093, 0.220134583700443, -0.0925601673405935]
                      ], dtype=np.float32)

        y = np.array([[0], [1], [0], [1], [1]])

        groups = np.array(
            [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19], [20, 21, 22, 23, 24]])

        n_samples, n_features = X.shape
        y = np.atleast_1d(y)
        max_grouped_features = max([len(groups[i]) for i in range(len(groups))])
        min_samples_leaf = 1
        min_weight_leaf = 0
        random_state = check_random_state(2457)

        if y.ndim == 1:
            y = np.reshape(y, (-1, 1))

        n_outputs = y.shape[1]

        y = np.copy(y)

        classes = []
        n_classes = []

        y_encoded = np.zeros(y.shape, dtype=np.float64)
        for k in range(n_outputs):
            classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
            classes.append(classes_k)
            n_classes.append(classes_k.shape[0])

        y = y_encoded

        n_classes = np.array(n_classes, dtype=np.intp)

        criterion = CARTGVGini(n_outputs, n_classes)

        splitter = CARTGVSplitter(criterion, max_grouped_features, len(groups),
                                     min_samples_leaf, min_weight_leaf,
                                     random_state)

        sample_weight = None
        splitter.test_init(X, y, sample_weight, groups)

        start = 0
        end = n_samples
        weighted_n_node_samples = 0
        splitter.test_node_reset(start, end, weighted_n_node_samples)

        node_impurity = splitter.test_node_impurity()
        self.assertTrue(node_impurity >= 0)

    def test_init_BaseDenseSplitter_v2(self):

        # df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)
        #
        # train = df.loc[df['Type'] == 'train']
        #
        # X = train.iloc[:, 2:]
        #
        # y = train['Y']
        #
        # g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
        # g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
        # g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
        # g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
        # g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]
        #
        # groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])

        X = np.array([[-0.962564615251298, -0.0818379297761482, -0.257129359665299, -1.20057124658537,
                       -1.67321037673198, -0.850857878613548, -1.12636943482486, 0.264691871869928, 0.823490524418768,
                       -0.289267055667413, 0.375612134943435, 0.689033636785644, -0.0755870733096488,
                       -0.253686040025422, -0.767686310824219, -0.47706960213735, 0.619681515116366, -0.718706304417254,
                       -0.625998377401577, 0.595352830214443, -0.826055466109155, 0.841770278364141, 0.525998122722698,
                       -0.305537695526707, -0.551540574269715],
                      [-0.0170226173861495, -0.575187308059669, -0.0550716676440694, -0.596082039595892,
                       -0.153767849941737, -0.152659395126548, 0.103284766044348, 0.945962098961183, 0.11395628892521,
                       -1.0314335555107, -0.24180964927081, -0.225116148572662, 1.75090409682049, 0.276212128428595,
                       -0.226985192750251, -0.688321496802469, 0.721869146316049, -0.0427129520106458, 1.71093452174155,
                       0.440414655312213, -0.219061974136534, 0.370516601227188, -0.579953711046926, -2.4756697600574,
                       -2.09969534371281],
                      [0.859846852829686, -0.196768997920202, -0.665097766775893, 1.49845086392502, 0.712519776986412,
                       0.63382801135412, 0.338132006534241, -1.17912479597116, 0.337710921150664, -0.404533729530606,
                       0.984579714687047, -1.16236566382262, -0.786198019602607, -0.753822112046281, -0.811264249392465,
                       -0.594151853267325, -0.322916128201519, -1.2934117213506, 0.531732629482942, -1.6136606736686,
                       -1.27887838930757, 0.678437793765498, -1.19080597429513, 1.11533360829611, -0.340409112584892],
                      [-1.46244895844162, 0.508777691805245, -0.42599215315616, -0.570342024814983, -1.13004768682085,
                       1.12406519881936, 0.251809560422478, -2.06632443310484, -1.23862336004496, 1.6527814698557,
                       0.336827946772908, -0.233201791535758, 0.590072797080428, 1.7453946472635, 1.02016573606479,
                       -0.813457453508146, -0.0745696971758758, 2.89463767013771, 0.158622453385045, -1.70880561223817,
                       0.132671092412739, -0.479946273307748, 0.11444508132886, 1.40287375218729, -0.344499428025485],
                      [-0.383681631574503, 1.19713456197882, -0.302078922002226, -0.544313316070517, 1.11301409047452,
                       0.0643648126207925, 0.623795834834719, 0.288528481567621, -0.618352387217919, -0.180420032776369,
                       -0.974252399377197, -0.78154085269986, 0.673878430962106, -0.14493184535421, -1.58840476437875,
                       -0.89040398934659, -0.464336091106138, -0.804400496705168, 0.542582301058101, -0.213424538311193,
                       -0.925675256270349, 0.306707969484467, 0.378645850648093, 0.220134583700443, -0.0925601673405935]
                      ], dtype=np.float32)

        y = np.array([[0], [1], [0], [1], [1]])

        groups = np.array(
            [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19], [20, 21, 22, 23, 24]])

        y = np.atleast_1d(y)
        max_grouped_features = max([len(groups[i]) for i in range(len(groups))])
        min_samples_leaf = 1
        min_weight_leaf = 0
        random_state = np.random.RandomState(2547)

        if y.ndim == 1:
            y = np.reshape(y, (-1, 1))

        n_outputs = y.shape[1]

        y = np.copy(y)

        classes = []
        n_classes = []

        y_encoded = np.zeros(y.shape, dtype=np.float64)
        for k in range(n_outputs):
            classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
            classes.append(classes_k)
            n_classes.append(classes_k.shape[0])

        y = y_encoded

        n_classes = np.array(n_classes, dtype=np.intp)

        criterion = CARTGVGini(n_outputs, n_classes)

        splitter = BaseDenseCARTGVSplitter(criterion, max_grouped_features, len(groups),
                                     min_samples_leaf, min_weight_leaf,
                                     random_state)

        sample_weight = None
        res = splitter.test_init(X, y, sample_weight, groups) #X.to_numpy(dtype=np.float32)

        self.assertEqual(res, 0)
        # self.assertTrue(np.array(splitter.samples).all() == np.arange(X.shape[0]).all())
        self.assertEqual(splitter.n_samples, X.shape[0])
        self.assertEqual(splitter.weighted_n_samples, X.shape[0])
        # self.assertTrue((splitter.features).all() == np.arange(X.shape[1]).all())
        self.assertEqual(splitter.n_features, X.shape[1])  # Est ce que c'est vraiment cela que l'on veut ???
        # self.assertTrue(y.all() == np.asarray(splitter.y).all())
        if sample_weight != None:
            self.assertTrue(np.asarray(splitter.sample_weight).all() == sample_weight.all())
        # self.assertTrue(np.array(splitter.groups).all() == groups.all())
        self.assertEqual(splitter.n_groups, len(groups))
        # self.assertTrue(np.array(splitter.len_groups).all() == np.array([len(group) for group in groups]).all())
        # self.assertTrue(X.all().all() == np.array(splitter.X).all().all())

    def test_group_sample_BestCARTGVSplitter_v2(self):
        # df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)
        #
        # train = df.loc[df['Type'] == 'train']
        #
        # X = train.iloc[:, 2:]
        #
        # y = train['Y']
        #
        # g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
        # g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
        # g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
        # g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
        # g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]
        #
        # groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])

        X = np.array([[-0.962564615251298, -0.0818379297761482, -0.257129359665299, -1.20057124658537,
                       -1.67321037673198, -0.850857878613548, -1.12636943482486, 0.264691871869928, 0.823490524418768,
                       -0.289267055667413, 0.375612134943435, 0.689033636785644, -0.0755870733096488,
                       -0.253686040025422, -0.767686310824219, -0.47706960213735, 0.619681515116366, -0.718706304417254,
                       -0.625998377401577, 0.595352830214443, -0.826055466109155, 0.841770278364141, 0.525998122722698,
                       -0.305537695526707, -0.551540574269715],
                      [-0.0170226173861495, -0.575187308059669, -0.0550716676440694, -0.596082039595892,
                       -0.153767849941737, -0.152659395126548, 0.103284766044348, 0.945962098961183, 0.11395628892521,
                       -1.0314335555107, -0.24180964927081, -0.225116148572662, 1.75090409682049, 0.276212128428595,
                       -0.226985192750251, -0.688321496802469, 0.721869146316049, -0.0427129520106458, 1.71093452174155,
                       0.440414655312213, -0.219061974136534, 0.370516601227188, -0.579953711046926, -2.4756697600574,
                       -2.09969534371281],
                      [0.859846852829686, -0.196768997920202, -0.665097766775893, 1.49845086392502, 0.712519776986412,
                       0.63382801135412, 0.338132006534241, -1.17912479597116, 0.337710921150664, -0.404533729530606,
                       0.984579714687047, -1.16236566382262, -0.786198019602607, -0.753822112046281, -0.811264249392465,
                       -0.594151853267325, -0.322916128201519, -1.2934117213506, 0.531732629482942, -1.6136606736686,
                       -1.27887838930757, 0.678437793765498, -1.19080597429513, 1.11533360829611, -0.340409112584892],
                      [-1.46244895844162, 0.508777691805245, -0.42599215315616, -0.570342024814983, -1.13004768682085,
                       1.12406519881936, 0.251809560422478, -2.06632443310484, -1.23862336004496, 1.6527814698557,
                       0.336827946772908, -0.233201791535758, 0.590072797080428, 1.7453946472635, 1.02016573606479,
                       -0.813457453508146, -0.0745696971758758, 2.89463767013771, 0.158622453385045, -1.70880561223817,
                       0.132671092412739, -0.479946273307748, 0.11444508132886, 1.40287375218729, -0.344499428025485],
                      [-0.383681631574503, 1.19713456197882, -0.302078922002226, -0.544313316070517, 1.11301409047452,
                       0.0643648126207925, 0.623795834834719, 0.288528481567621, -0.618352387217919, -0.180420032776369,
                       -0.974252399377197, -0.78154085269986, 0.673878430962106, -0.14493184535421, -1.58840476437875,
                       -0.89040398934659, -0.464336091106138, -0.804400496705168, 0.542582301058101, -0.213424538311193,
                       -0.925675256270349, 0.306707969484467, 0.378645850648093, 0.220134583700443, -0.0925601673405935]
                      ], dtype=np.float32)

        y = np.array([[0], [1], [0], [1], [1]])

        groups = np.array(
            [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19], [20, 21, 22, 23, 24]])

        n_samples, n_features = X.shape
        y = np.atleast_1d(y)
        max_grouped_features = max([len(groups[i]) for i in range(len(groups))])
        min_samples_leaf = 1
        min_weight_leaf = 0
        random_state = check_random_state(2457)

        if y.ndim == 1:
            y = np.reshape(y, (-1, 1))

        n_outputs = y.shape[1]

        y = np.copy(y)

        classes = []
        n_classes = []

        y_encoded = np.zeros(y.shape, dtype=np.float64)
        for k in range(n_outputs):
            classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
            classes.append(classes_k)
            n_classes.append(classes_k.shape[0])

        y = y_encoded

        n_classes = np.array(n_classes, dtype=np.intp)

        criterion = CARTGVGini(n_outputs, n_classes)

        splitter = BestCARTGVSplitter(criterion, max_grouped_features, len(groups),
                                     min_samples_leaf, min_weight_leaf,
                                     random_state)

        sample_weight = None
        splitter.test_init(X, y, sample_weight, groups) #X.to_numpy(dtype=np.float32)

        start = 0
        end = n_samples
        weighted_n_node_samples = 0
        splitter.test_node_reset(start, end, weighted_n_node_samples)

        Xf = splitter.test_group_sample(groups[0], len(groups[0]), start, end)

        # self.assertEqual(Xf.all(), np.array(X)[:,groups[0][0]:len(groups[0])].all())

    def test_reset_scikit_learn_instances_BestCARTGVSplitter_v2(self):

        # df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)
        #
        # train = df.loc[df['Type'] == 'train']
        #
        # X = train.iloc[:, 2:]
        #
        # y = train['Y']
        #
        # g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
        # g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
        # g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
        # g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
        # g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]
        #
        # groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])

        X = np.array([[-0.962564615251298, -0.0818379297761482, -0.257129359665299, -1.20057124658537,
                       -1.67321037673198, -0.850857878613548, -1.12636943482486, 0.264691871869928, 0.823490524418768,
                       -0.289267055667413, 0.375612134943435, 0.689033636785644, -0.0755870733096488,
                       -0.253686040025422, -0.767686310824219, -0.47706960213735, 0.619681515116366, -0.718706304417254,
                       -0.625998377401577, 0.595352830214443, -0.826055466109155, 0.841770278364141, 0.525998122722698,
                       -0.305537695526707, -0.551540574269715],
                      [-0.0170226173861495, -0.575187308059669, -0.0550716676440694, -0.596082039595892,
                       -0.153767849941737, -0.152659395126548, 0.103284766044348, 0.945962098961183, 0.11395628892521,
                       -1.0314335555107, -0.24180964927081, -0.225116148572662, 1.75090409682049, 0.276212128428595,
                       -0.226985192750251, -0.688321496802469, 0.721869146316049, -0.0427129520106458, 1.71093452174155,
                       0.440414655312213, -0.219061974136534, 0.370516601227188, -0.579953711046926, -2.4756697600574,
                       -2.09969534371281],
                      [0.859846852829686, -0.196768997920202, -0.665097766775893, 1.49845086392502, 0.712519776986412,
                       0.63382801135412, 0.338132006534241, -1.17912479597116, 0.337710921150664, -0.404533729530606,
                       0.984579714687047, -1.16236566382262, -0.786198019602607, -0.753822112046281, -0.811264249392465,
                       -0.594151853267325, -0.322916128201519, -1.2934117213506, 0.531732629482942, -1.6136606736686,
                       -1.27887838930757, 0.678437793765498, -1.19080597429513, 1.11533360829611, -0.340409112584892],
                      [-1.46244895844162, 0.508777691805245, -0.42599215315616, -0.570342024814983, -1.13004768682085,
                       1.12406519881936, 0.251809560422478, -2.06632443310484, -1.23862336004496, 1.6527814698557,
                       0.336827946772908, -0.233201791535758, 0.590072797080428, 1.7453946472635, 1.02016573606479,
                       -0.813457453508146, -0.0745696971758758, 2.89463767013771, 0.158622453385045, -1.70880561223817,
                       0.132671092412739, -0.479946273307748, 0.11444508132886, 1.40287375218729, -0.344499428025485],
                      [-0.383681631574503, 1.19713456197882, -0.302078922002226, -0.544313316070517, 1.11301409047452,
                       0.0643648126207925, 0.623795834834719, 0.288528481567621, -0.618352387217919, -0.180420032776369,
                       -0.974252399377197, -0.78154085269986, 0.673878430962106, -0.14493184535421, -1.58840476437875,
                       -0.89040398934659, -0.464336091106138, -0.804400496705168, 0.542582301058101, -0.213424538311193,
                       -0.925675256270349, 0.306707969484467, 0.378645850648093, 0.220134583700443, -0.0925601673405935]
                      ], dtype=np.float32)

        y = np.array([[0], [1], [0], [1], [1]])

        groups = np.array(
            [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19], [20, 21, 22, 23, 24]])

        n_samples, n_features = X.shape
        y = np.atleast_1d(y)
        max_grouped_features = max([len(groups[i]) for i in range(len(groups))])
        min_samples_leaf = 1
        min_weight_leaf = 0
        random_state = check_random_state(2457)

        if y.ndim == 1:
            y = np.reshape(y, (-1, 1))

        n_outputs = y.shape[1]

        y = np.copy(y)

        classes = []
        n_classes = []

        y_encoded = np.zeros(y.shape, dtype=np.float64)
        for k in range(n_outputs):
            classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
            classes.append(classes_k)
            n_classes.append(classes_k.shape[0])

        y = y_encoded

        n_classes = np.array(n_classes, dtype=np.intp)

        criterion = CARTGVGini(n_outputs, n_classes)

        splitter = BestCARTGVSplitter(criterion, max_grouped_features, len(groups),
                                         min_samples_leaf, min_weight_leaf,
                                         random_state)

        sample_weight = None
        splitter.test_init(X, y, sample_weight, groups) #X.to_numpy(dtype=np.float32)

        start = 0
        end = n_samples
        weighted_n_node_samples = 0
        splitter.test_node_reset(start, end, weighted_n_node_samples)
        splitter.test_reset_scikit_learn_instances(y, len(groups[0]))

        tree = Tree(len(groups[0]), n_classes, n_outputs)

        self.assertEqual(type(splitter.splitting_tree), type(tree))
        self.assertEqual(splitter.splitting_tree.n_features, tree.n_features)
        self.assertEqual(splitter.splitting_tree.n_outputs, tree.n_outputs)
        # self.assertEqual(np.array(splitter.splitting_tree.n_classes).all(), np.array(tree.n_classes).all())
        self.assertEqual(splitter.splitting_tree.max_n_classes, tree.max_n_classes)
        self.assertEqual(splitter.splitting_tree.max_depth, tree.max_depth)
        self.assertEqual(splitter.splitting_tree.node_count, tree.node_count)
        self.assertEqual(splitter.splitting_tree.capacity, tree.capacity)
        # self.assertEqual(splitter.splitting_tree.value.all(), tree.value.all())

        max_features = len(groups[0])
        min_samples_leaf = 1
        min_samples_split = 2
        min_weight_leaf = 0.0
        max_depth = 3
        min_impurity_decrease = 0.
        min_impurity_split = 0.
        random_state = np.random.RandomState(2547)

        criterion = Gini(n_outputs, n_classes)

        spltr = BestSplitter(criterion, max_features, min_samples_leaf, min_weight_leaf, random_state)

        depthFirstTreeBuilder = DepthFirstTreeBuilder(spltr, min_samples_split, min_samples_leaf, min_weight_leaf,
                                                      max_depth, min_impurity_decrease, min_impurity_split)

        ### CAN'T TEST BECAUSE THEY AREN'T PROPERTIES IN SCIKIT-LEARN ###

        self.assertEqual(type(splitter.splitting_tree_builder),type(depthFirstTreeBuilder))
        # self.assertEqual(type(splitter.splitting_tree_builder.splitter),type(depthFirstTreeBuilder.splitter))
        # self.assertEqual(splitter.splitting_tree_builder.min_samples_split, min_samples_split)
        # self.assertEqual(splitter.splitting_tree_builder.min_samples_leaf,min_samples_leaf)
        # self.assertEqual(splitter.splitting_tree_builder.min_weight_leaf,min_weight_leaf)
        # self.assertEqual(splitter.splitting_tree_builder.max_depth,max_depth)
        # self.assertEqual(splitter.splitting_tree_builder.min_impurity_decrease, min_impurity_decrease)
        # self.assertEqual(splitter.splitting_tree_builder.min_impurity_split, min_impurity_split)

    def test_n_reset_scikit_learn_instances_BestCARTGVSplitter_v2(self):

        # df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)
        #
        # train = df.loc[df['Type'] == 'train']
        #
        # X = train.iloc[:, 2:]
        #
        # y = train['Y']
        #
        # g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
        # g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
        # g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
        # g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
        # g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]
        #
        # groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])

        X = np.array([[-0.962564615251298, -0.0818379297761482, -0.257129359665299, -1.20057124658537,
                       -1.67321037673198, -0.850857878613548, -1.12636943482486, 0.264691871869928, 0.823490524418768,
                       -0.289267055667413, 0.375612134943435, 0.689033636785644, -0.0755870733096488,
                       -0.253686040025422, -0.767686310824219, -0.47706960213735, 0.619681515116366, -0.718706304417254,
                       -0.625998377401577, 0.595352830214443, -0.826055466109155, 0.841770278364141, 0.525998122722698,
                       -0.305537695526707, -0.551540574269715],
                      [-0.0170226173861495, -0.575187308059669, -0.0550716676440694, -0.596082039595892,
                       -0.153767849941737, -0.152659395126548, 0.103284766044348, 0.945962098961183, 0.11395628892521,
                       -1.0314335555107, -0.24180964927081, -0.225116148572662, 1.75090409682049, 0.276212128428595,
                       -0.226985192750251, -0.688321496802469, 0.721869146316049, -0.0427129520106458, 1.71093452174155,
                       0.440414655312213, -0.219061974136534, 0.370516601227188, -0.579953711046926, -2.4756697600574,
                       -2.09969534371281],
                      [0.859846852829686, -0.196768997920202, -0.665097766775893, 1.49845086392502, 0.712519776986412,
                       0.63382801135412, 0.338132006534241, -1.17912479597116, 0.337710921150664, -0.404533729530606,
                       0.984579714687047, -1.16236566382262, -0.786198019602607, -0.753822112046281, -0.811264249392465,
                       -0.594151853267325, -0.322916128201519, -1.2934117213506, 0.531732629482942, -1.6136606736686,
                       -1.27887838930757, 0.678437793765498, -1.19080597429513, 1.11533360829611, -0.340409112584892],
                      [-1.46244895844162, 0.508777691805245, -0.42599215315616, -0.570342024814983, -1.13004768682085,
                       1.12406519881936, 0.251809560422478, -2.06632443310484, -1.23862336004496, 1.6527814698557,
                       0.336827946772908, -0.233201791535758, 0.590072797080428, 1.7453946472635, 1.02016573606479,
                       -0.813457453508146, -0.0745696971758758, 2.89463767013771, 0.158622453385045, -1.70880561223817,
                       0.132671092412739, -0.479946273307748, 0.11444508132886, 1.40287375218729, -0.344499428025485],
                      [-0.383681631574503, 1.19713456197882, -0.302078922002226, -0.544313316070517, 1.11301409047452,
                       0.0643648126207925, 0.623795834834719, 0.288528481567621, -0.618352387217919, -0.180420032776369,
                       -0.974252399377197, -0.78154085269986, 0.673878430962106, -0.14493184535421, -1.58840476437875,
                       -0.89040398934659, -0.464336091106138, -0.804400496705168, 0.542582301058101, -0.213424538311193,
                       -0.925675256270349, 0.306707969484467, 0.378645850648093, 0.220134583700443, -0.0925601673405935]
                      ], dtype=np.float32)

        y = np.array([[0], [1], [0], [1], [1]])

        groups = np.array(
            [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19], [20, 21, 22, 23, 24]])

        n_samples, n_features = X.shape
        y = np.atleast_1d(y)
        max_grouped_features = max([len(groups[i]) for i in range(len(groups))])
        min_samples_leaf = 1
        min_weight_leaf = 0
        random_state = np.random.RandomState(2547)

        if y.ndim == 1:
            y = np.reshape(y, (-1, 1))

        n_outputs = y.shape[1]

        y = np.copy(y)

        classes = []
        n_classes = []

        y_encoded = np.zeros(y.shape, dtype=np.float64)
        for k in range(n_outputs):
            classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
            classes.append(classes_k)
            n_classes.append(classes_k.shape[0])

        y = y_encoded

        n_classes = np.array(n_classes, dtype=np.intp)

        criterion = CARTGVGini(n_outputs, n_classes)

        splitter = BestCARTGVSplitter(criterion, max_grouped_features, len(groups),
                                         min_samples_leaf, min_weight_leaf,
                                         random_state)

        sample_weight = None
        splitter.test_init(X, y, sample_weight, groups) #X.to_numpy(dtype=np.float32)

        start = 0
        end = n_samples
        weighted_n_node_samples = 0
        splitter.test_node_reset(start, end, weighted_n_node_samples)

        for i in range(5):

            splitter.test_reset_scikit_learn_instances(y, len(groups[0]))

            tree = Tree(len(groups[0]), n_classes, n_outputs)

            self.assertEqual(type(splitter.splitting_tree), type(tree))
            self.assertEqual(splitter.splitting_tree.n_features, tree.n_features)
            self.assertEqual(splitter.splitting_tree.n_outputs, tree.n_outputs)
            # self.assertEqual(np.array(splitter.splitting_tree.n_classes).all(), np.array(tree.n_classes).all())
            self.assertEqual(splitter.splitting_tree.max_n_classes, tree.max_n_classes)
            self.assertEqual(splitter.splitting_tree.max_depth, tree.max_depth)
            self.assertEqual(splitter.splitting_tree.node_count, tree.node_count)
            self.assertEqual(splitter.splitting_tree.capacity, tree.capacity)
            # self.assertEqual(splitter.splitting_tree.value.all(), tree.value.all())

            max_features = len(groups[0])
            min_samples_leaf = 1
            min_samples_split = 2
            min_weight_leaf = 0.0
            max_depth = 3
            min_impurity_decrease = 0.
            min_impurity_split = 0.
            random_state = np.random.RandomState(2547)

            criterion = Gini(n_outputs, n_classes)

            spltr = BestSplitter(criterion, max_features, min_samples_leaf, min_weight_leaf, random_state)

            depthFirstTreeBuilder = DepthFirstTreeBuilder(spltr, min_samples_split, min_samples_leaf, min_weight_leaf,
                                                          max_depth, min_impurity_decrease, min_impurity_split)

            ### CAN'T TEST BECAUSE THEY AREN'T PROPERTIES IN SCIKIT-LEARN ###

            self.assertEqual(type(splitter.splitting_tree_builder),type(depthFirstTreeBuilder))
            # self.assertEqual(type(splitter.splitting_tree_builder.splitter),type(depthFirstTreeBuilder.splitter))
            # self.assertEqual(splitter.splitting_tree_builder.min_samples_split, min_samples_split)
            # self.assertEqual(splitter.splitting_tree_builder.min_samples_leaf,min_samples_leaf)
            # self.assertEqual(splitter.splitting_tree_builder.min_weight_leaf,min_weight_leaf)
            # self.assertEqual(splitter.splitting_tree_builder.max_depth,max_depth)
            # self.assertEqual(splitter.splitting_tree_builder.min_impurity_decrease, min_impurity_decrease)
            # self.assertEqual(splitter.splitting_tree_builder.min_impurity_split, min_impurity_split)

    def test_splitting_tree_construction_BestCARTGVSplitter_v2(self):
        # df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)
        #
        # train = df.loc[df['Type'] == 'train']
        #
        # X = train.iloc[:, 2:]
        #
        # y = train['Y']
        #
        # g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
        # g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
        # g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
        # g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
        # g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]
        #
        # groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])

        X = np.array([[-0.962564615251298, -0.0818379297761482, -0.257129359665299, -1.20057124658537,
                       -1.67321037673198, -0.850857878613548, -1.12636943482486, 0.264691871869928, 0.823490524418768,
                       -0.289267055667413, 0.375612134943435, 0.689033636785644, -0.0755870733096488,
                       -0.253686040025422, -0.767686310824219, -0.47706960213735, 0.619681515116366, -0.718706304417254,
                       -0.625998377401577, 0.595352830214443, -0.826055466109155, 0.841770278364141, 0.525998122722698,
                       -0.305537695526707, -0.551540574269715],
                      [-0.0170226173861495, -0.575187308059669, -0.0550716676440694, -0.596082039595892,
                       -0.153767849941737, -0.152659395126548, 0.103284766044348, 0.945962098961183, 0.11395628892521,
                       -1.0314335555107, -0.24180964927081, -0.225116148572662, 1.75090409682049, 0.276212128428595,
                       -0.226985192750251, -0.688321496802469, 0.721869146316049, -0.0427129520106458, 1.71093452174155,
                       0.440414655312213, -0.219061974136534, 0.370516601227188, -0.579953711046926, -2.4756697600574,
                       -2.09969534371281],
                      [0.859846852829686, -0.196768997920202, -0.665097766775893, 1.49845086392502, 0.712519776986412,
                       0.63382801135412, 0.338132006534241, -1.17912479597116, 0.337710921150664, -0.404533729530606,
                       0.984579714687047, -1.16236566382262, -0.786198019602607, -0.753822112046281, -0.811264249392465,
                       -0.594151853267325, -0.322916128201519, -1.2934117213506, 0.531732629482942, -1.6136606736686,
                       -1.27887838930757, 0.678437793765498, -1.19080597429513, 1.11533360829611, -0.340409112584892],
                      [-1.46244895844162, 0.508777691805245, -0.42599215315616, -0.570342024814983, -1.13004768682085,
                       1.12406519881936, 0.251809560422478, -2.06632443310484, -1.23862336004496, 1.6527814698557,
                       0.336827946772908, -0.233201791535758, 0.590072797080428, 1.7453946472635, 1.02016573606479,
                       -0.813457453508146, -0.0745696971758758, 2.89463767013771, 0.158622453385045, -1.70880561223817,
                       0.132671092412739, -0.479946273307748, 0.11444508132886, 1.40287375218729, -0.344499428025485],
                      [-0.383681631574503, 1.19713456197882, -0.302078922002226, -0.544313316070517, 1.11301409047452,
                       0.0643648126207925, 0.623795834834719, 0.288528481567621, -0.618352387217919, -0.180420032776369,
                       -0.974252399377197, -0.78154085269986, 0.673878430962106, -0.14493184535421, -1.58840476437875,
                       -0.89040398934659, -0.464336091106138, -0.804400496705168, 0.542582301058101, -0.213424538311193,
                       -0.925675256270349, 0.306707969484467, 0.378645850648093, 0.220134583700443, -0.0925601673405935]
                      ], dtype=np.float32)

        y = np.array([[0], [1], [0], [1], [1]])

        groups = np.array(
            [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19], [20, 21, 22, 23, 24]])

        n_samples, n_features = X.shape
        y = np.atleast_1d(y)
        max_grouped_features = max([len(groups[i]) for i in range(len(groups))])
        min_samples_leaf = 1
        min_weight_leaf = 0
        random_state = check_random_state(2457)

        if y.ndim == 1:
            y = np.reshape(y, (-1, 1))

        n_outputs = y.shape[1]

        y = np.copy(y)

        classes = []
        n_classes = []

        y_encoded = np.zeros(y.shape, dtype=np.float64)
        for k in range(n_outputs):
            classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
            classes.append(classes_k)
            n_classes.append(classes_k.shape[0])

        y = y_encoded

        n_classes = np.array(n_classes, dtype=np.intp)

        criterion = CARTGVGini(n_outputs, n_classes)

        splitter = BestCARTGVSplitter(criterion, max_grouped_features, len(groups),
                                         min_samples_leaf, min_weight_leaf,
                                         random_state)

        sample_weight = None
        splitter.test_init(X, y, sample_weight, groups) #X.to_numpy(dtype=np.float32)

        start = 0
        end = n_samples
        weighted_n_node_samples = 0
        splitter.test_node_reset(start, end, weighted_n_node_samples)

        Xf = splitter.test_group_sample(groups[0], len(groups[0]), start, end)
        splitter.test_reset_scikit_learn_instances(y, len(groups[0]))
        splitter.test_splitting_tree_construction(Xf,y)

        tree = Tree(len(groups[0]), n_classes, n_outputs)

        max_features = len(groups[0])
        min_samples_leaf = 1
        min_samples_split = 2
        min_weight_leaf = 0.0
        max_depth = 3
        min_impurity_decrease = 0.
        min_impurity_split = 0.
        random_state = np.random.RandomState(2547)

        criterion = Gini(n_outputs, n_classes)

        spltr = BestSplitter(criterion, max_features, min_samples_leaf, min_weight_leaf, random_state)

        depthFirstTreeBuilder = DepthFirstTreeBuilder(spltr, min_samples_split, min_samples_leaf, min_weight_leaf,
                                                      max_depth, min_impurity_decrease, min_impurity_split)

        depthFirstTreeBuilder.build(tree,Xf,y)

        self.assertEqual(type(splitter.splitting_tree), type(tree))
        self.assertEqual(splitter.splitting_tree.n_features, tree.n_features)
        self.assertEqual(splitter.splitting_tree.n_outputs, tree.n_outputs)
        # self.assertEqual(np.array(splitter.splitting_tree.n_classes).all(), np.array(tree.n_classes).all())
        self.assertEqual(splitter.splitting_tree.max_n_classes, tree.max_n_classes)
        self.assertEqual(splitter.splitting_tree.max_depth, tree.max_depth)
        self.assertEqual(splitter.splitting_tree.node_count, tree.node_count)
        self.assertEqual(splitter.splitting_tree.capacity, tree.capacity)
        # self.assertEqual(splitter.splitting_tree.value.all(), tree.value.all())

    def test_n_splitting_tree_construction_BestCARTGVSplitter_v2(self):
        # df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)
        #
        # train = df.loc[df['Type'] == 'train']
        #
        # X = train.iloc[:, 2:]
        #
        # y = train['Y']
        #
        # g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
        # g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
        # g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
        # g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
        # g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]
        #
        # groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])

        X = np.array([[-0.962564615251298, -0.0818379297761482, -0.257129359665299, -1.20057124658537,
                       -1.67321037673198, -0.850857878613548, -1.12636943482486, 0.264691871869928, 0.823490524418768,
                       -0.289267055667413, 0.375612134943435, 0.689033636785644, -0.0755870733096488,
                       -0.253686040025422, -0.767686310824219, -0.47706960213735, 0.619681515116366, -0.718706304417254,
                       -0.625998377401577, 0.595352830214443, -0.826055466109155, 0.841770278364141, 0.525998122722698,
                       -0.305537695526707, -0.551540574269715],
                      [-0.0170226173861495, -0.575187308059669, -0.0550716676440694, -0.596082039595892,
                       -0.153767849941737, -0.152659395126548, 0.103284766044348, 0.945962098961183, 0.11395628892521,
                       -1.0314335555107, -0.24180964927081, -0.225116148572662, 1.75090409682049, 0.276212128428595,
                       -0.226985192750251, -0.688321496802469, 0.721869146316049, -0.0427129520106458, 1.71093452174155,
                       0.440414655312213, -0.219061974136534, 0.370516601227188, -0.579953711046926, -2.4756697600574,
                       -2.09969534371281],
                      [0.859846852829686, -0.196768997920202, -0.665097766775893, 1.49845086392502, 0.712519776986412,
                       0.63382801135412, 0.338132006534241, -1.17912479597116, 0.337710921150664, -0.404533729530606,
                       0.984579714687047, -1.16236566382262, -0.786198019602607, -0.753822112046281, -0.811264249392465,
                       -0.594151853267325, -0.322916128201519, -1.2934117213506, 0.531732629482942, -1.6136606736686,
                       -1.27887838930757, 0.678437793765498, -1.19080597429513, 1.11533360829611, -0.340409112584892],
                      [-1.46244895844162, 0.508777691805245, -0.42599215315616, -0.570342024814983, -1.13004768682085,
                       1.12406519881936, 0.251809560422478, -2.06632443310484, -1.23862336004496, 1.6527814698557,
                       0.336827946772908, -0.233201791535758, 0.590072797080428, 1.7453946472635, 1.02016573606479,
                       -0.813457453508146, -0.0745696971758758, 2.89463767013771, 0.158622453385045, -1.70880561223817,
                       0.132671092412739, -0.479946273307748, 0.11444508132886, 1.40287375218729, -0.344499428025485],
                      [-0.383681631574503, 1.19713456197882, -0.302078922002226, -0.544313316070517, 1.11301409047452,
                       0.0643648126207925, 0.623795834834719, 0.288528481567621, -0.618352387217919, -0.180420032776369,
                       -0.974252399377197, -0.78154085269986, 0.673878430962106, -0.14493184535421, -1.58840476437875,
                       -0.89040398934659, -0.464336091106138, -0.804400496705168, 0.542582301058101, -0.213424538311193,
                       -0.925675256270349, 0.306707969484467, 0.378645850648093, 0.220134583700443, -0.0925601673405935]
                      ], dtype=np.float32)

        y = np.array([[0], [1], [0], [1], [1]])

        groups = np.array(
            [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19], [20, 21, 22, 23, 24]])

        n_samples, n_features = X.shape
        y = np.atleast_1d(y)
        max_grouped_features = max([len(groups[i]) for i in range(len(groups))])
        min_samples_leaf = 1
        min_weight_leaf = 0
        random_state = check_random_state(2457)

        if y.ndim == 1:
            y = np.reshape(y, (-1, 1))

        n_outputs = y.shape[1]

        y = np.copy(y)

        classes = []
        n_classes = []

        y_encoded = np.zeros(y.shape, dtype=np.float64)
        for k in range(n_outputs):
            classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
            classes.append(classes_k)
            n_classes.append(classes_k.shape[0])

        y = y_encoded

        n_classes = np.array(n_classes, dtype=np.intp)

        criterion = CARTGVGini(n_outputs, n_classes)

        splitter = BestCARTGVSplitter(criterion, max_grouped_features, len(groups),
                                         min_samples_leaf, min_weight_leaf,
                                         random_state)

        sample_weight = None
        splitter.test_init(X, y, sample_weight, groups) #X.to_numpy(dtype=np.float32)

        start = 0
        end = n_samples
        weighted_n_node_samples = 0
        splitter.test_node_reset(start, end, weighted_n_node_samples)

        for i in range(5):
            Xf = splitter.test_group_sample(groups[0], len(groups[0]), start, end)
            splitter.test_reset_scikit_learn_instances(y, len(groups[0]))
            splitter.test_splitting_tree_construction(Xf,y)

            tree = Tree(len(groups[0]), n_classes, n_outputs)

            max_features = len(groups[0])
            min_samples_leaf = 1
            min_samples_split = 2
            min_weight_leaf = 0.0
            max_depth = 3
            min_impurity_decrease = 0.
            min_impurity_split = 0.
            random_state = np.random.RandomState(2547)

            criterion = Gini(n_outputs, n_classes)

            spltr = BestSplitter(criterion, max_features, min_samples_leaf, min_weight_leaf, random_state)

            depthFirstTreeBuilder = DepthFirstTreeBuilder(spltr, min_samples_split, min_samples_leaf, min_weight_leaf,
                                                          max_depth, min_impurity_decrease, min_impurity_split)

            depthFirstTreeBuilder.build(tree,Xf,y)

            self.assertEqual(type(splitter.splitting_tree), type(tree))
            self.assertEqual(splitter.splitting_tree.n_features, tree.n_features)
            self.assertEqual(splitter.splitting_tree.n_outputs, tree.n_outputs)
            # self.assertEqual(np.array(splitter.splitting_tree.n_classes).all(), np.array(tree.n_classes).all())
            self.assertEqual(splitter.splitting_tree.max_n_classes, tree.max_n_classes)
            self.assertEqual(splitter.splitting_tree.max_depth, tree.max_depth)
            self.assertEqual(splitter.splitting_tree.node_count, tree.node_count)
            self.assertEqual(splitter.splitting_tree.capacity, tree.capacity)
            # self.assertEqual(splitter.splitting_tree.value.all(), tree.value.all())

    def test_get_splitting_tree_leaves_BestCARTGVSplitter_v2(self):

        # df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)
        #
        # train = df.loc[df['Type'] == 'train']
        #
        # X = train.iloc[:, 2:]
        #
        # y = train['Y']
        #
        # g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
        # g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
        # g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
        # g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
        # g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]
        #
        # groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])

        X = np.array([[-0.962564615251298, -0.0818379297761482, -0.257129359665299, -1.20057124658537,
                       -1.67321037673198, -0.850857878613548, -1.12636943482486, 0.264691871869928, 0.823490524418768,
                       -0.289267055667413, 0.375612134943435, 0.689033636785644, -0.0755870733096488,
                       -0.253686040025422, -0.767686310824219, -0.47706960213735, 0.619681515116366, -0.718706304417254,
                       -0.625998377401577, 0.595352830214443, -0.826055466109155, 0.841770278364141, 0.525998122722698,
                       -0.305537695526707, -0.551540574269715],
                      [-0.0170226173861495, -0.575187308059669, -0.0550716676440694, -0.596082039595892,
                       -0.153767849941737, -0.152659395126548, 0.103284766044348, 0.945962098961183, 0.11395628892521,
                       -1.0314335555107, -0.24180964927081, -0.225116148572662, 1.75090409682049, 0.276212128428595,
                       -0.226985192750251, -0.688321496802469, 0.721869146316049, -0.0427129520106458, 1.71093452174155,
                       0.440414655312213, -0.219061974136534, 0.370516601227188, -0.579953711046926, -2.4756697600574,
                       -2.09969534371281],
                      [0.859846852829686, -0.196768997920202, -0.665097766775893, 1.49845086392502, 0.712519776986412,
                       0.63382801135412, 0.338132006534241, -1.17912479597116, 0.337710921150664, -0.404533729530606,
                       0.984579714687047, -1.16236566382262, -0.786198019602607, -0.753822112046281, -0.811264249392465,
                       -0.594151853267325, -0.322916128201519, -1.2934117213506, 0.531732629482942, -1.6136606736686,
                       -1.27887838930757, 0.678437793765498, -1.19080597429513, 1.11533360829611, -0.340409112584892],
                      [-1.46244895844162, 0.508777691805245, -0.42599215315616, -0.570342024814983, -1.13004768682085,
                       1.12406519881936, 0.251809560422478, -2.06632443310484, -1.23862336004496, 1.6527814698557,
                       0.336827946772908, -0.233201791535758, 0.590072797080428, 1.7453946472635, 1.02016573606479,
                       -0.813457453508146, -0.0745696971758758, 2.89463767013771, 0.158622453385045, -1.70880561223817,
                       0.132671092412739, -0.479946273307748, 0.11444508132886, 1.40287375218729, -0.344499428025485],
                      [-0.383681631574503, 1.19713456197882, -0.302078922002226, -0.544313316070517, 1.11301409047452,
                       0.0643648126207925, 0.623795834834719, 0.288528481567621, -0.618352387217919, -0.180420032776369,
                       -0.974252399377197, -0.78154085269986, 0.673878430962106, -0.14493184535421, -1.58840476437875,
                       -0.89040398934659, -0.464336091106138, -0.804400496705168, 0.542582301058101, -0.213424538311193,
                       -0.925675256270349, 0.306707969484467, 0.378645850648093, 0.220134583700443, -0.0925601673405935]
                      ], dtype=np.float32)

        y = np.array([[0], [1], [0], [1], [1]])

        groups = np.array(
            [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19], [20, 21, 22, 23, 24]])

        n_samples, n_features = X.shape
        y = np.atleast_1d(y)
        max_grouped_features = max([len(groups[i]) for i in range(len(groups))])
        min_samples_leaf = 1
        min_weight_leaf = 0
        random_state = check_random_state(2457)

        if y.ndim == 1:
            y = np.reshape(y, (-1, 1))

        n_outputs = y.shape[1]

        y = np.copy(y)

        classes = []
        n_classes = []

        y_encoded = np.zeros(y.shape, dtype=np.float64)
        for k in range(n_outputs):
            classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
            classes.append(classes_k)
            n_classes.append(classes_k.shape[0])

        y = y_encoded

        n_classes = np.array(n_classes, dtype=np.intp)

        criterion = CARTGVGini(n_outputs, n_classes)

        splitter = BestCARTGVSplitter(criterion, max_grouped_features, len(groups),
                                         min_samples_leaf, min_weight_leaf,
                                         random_state)

        sample_weight = None
        splitter.test_init(X, y, sample_weight, groups) #X.to_numpy(dtype=np.float32)

        start = 0
        end = n_samples
        weighted_n_node_samples = 0
        splitter.test_node_reset(start, end, weighted_n_node_samples)

        Xf = splitter.test_group_sample(groups[0], len(groups[0]), start, end)
        splitter.test_reset_scikit_learn_instances(y, len(groups[0]))
        splitter.test_splitting_tree_construction(Xf, y)
        splitter.test_get_splitting_tree_leaves()

        max_depth = 3
        random_state = np.random.RandomState(2547)

        # clf = DecisionTreeClassifier(max_depth=max_depth, random_state=random_state, max_features=len(groups[0]),
        #                              max_leaf_nodes=X.shape[0])
        # tree = clf.fit(X.iloc[:, groups[0]], y)
        # fig, ax = plt.subplots(1, 2, figsize=(16, 9))
        # plot_tree(tree, ax=ax[0])

        # clf.tree_ = splitter.splitting_tree
        # plot_tree(tree, ax=ax[1])
        # plt.show()

    def test_get_splitting_tree_leaves_samples_and_pos_BestCARTGVSplitter_v2(self):

        df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)

        train = df.loc[df['Type'] == 'train']

        X = train.iloc[:, 2:]

        y = train['Y']

        g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
        g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
        g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
        g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
        g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]

        groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])

        # X = np.array([[-0.962564615251298,-0.0818379297761482,-0.257129359665299,-1.20057124658537,-1.67321037673198,-0.850857878613548,-1.12636943482486,0.264691871869928,0.823490524418768,-0.289267055667413,0.375612134943435,0.689033636785644,-0.0755870733096488,-0.253686040025422,-0.767686310824219,-0.47706960213735,0.619681515116366,-0.718706304417254,-0.625998377401577,0.595352830214443,-0.826055466109155,0.841770278364141,0.525998122722698,-0.305537695526707,-0.551540574269715],
        #               [-0.0170226173861495,-0.575187308059669,-0.0550716676440694,-0.596082039595892,-0.153767849941737,-0.152659395126548,0.103284766044348,0.945962098961183,0.11395628892521,-1.0314335555107,-0.24180964927081,-0.225116148572662,1.75090409682049,0.276212128428595,-0.226985192750251,-0.688321496802469,0.721869146316049,-0.0427129520106458,1.71093452174155,0.440414655312213,-0.219061974136534,0.370516601227188,-0.579953711046926,-2.4756697600574,-2.09969534371281],
        #               [0.859846852829686,-0.196768997920202,-0.665097766775893,1.49845086392502,0.712519776986412,0.63382801135412,0.338132006534241,-1.17912479597116,0.337710921150664,-0.404533729530606,0.984579714687047,-1.16236566382262,-0.786198019602607,-0.753822112046281,-0.811264249392465,-0.594151853267325,-0.322916128201519,-1.2934117213506,0.531732629482942,-1.6136606736686,-1.27887838930757,0.678437793765498,-1.19080597429513,1.11533360829611,-0.340409112584892],
        #               [-1.46244895844162,0.508777691805245,-0.42599215315616,-0.570342024814983,-1.13004768682085,1.12406519881936,0.251809560422478,-2.06632443310484,-1.23862336004496,1.6527814698557,0.336827946772908,-0.233201791535758,0.590072797080428,1.7453946472635,1.02016573606479,-0.813457453508146,-0.0745696971758758,2.89463767013771,0.158622453385045,-1.70880561223817,0.132671092412739,-0.479946273307748,0.11444508132886,1.40287375218729,-0.344499428025485],
        #               [-0.383681631574503,1.19713456197882,-0.302078922002226,-0.544313316070517,1.11301409047452,0.0643648126207925,0.623795834834719,0.288528481567621,-0.618352387217919,-0.180420032776369,-0.974252399377197,-0.78154085269986,0.673878430962106,-0.14493184535421,-1.58840476437875,-0.89040398934659,-0.464336091106138,-0.804400496705168,0.542582301058101,-0.213424538311193,-0.925675256270349,0.306707969484467,0.378645850648093,0.220134583700443,-0.0925601673405935]
        #               ],dtype=np.float32)
        #
        # y = np.array([[0],[1],[0],[1],[1]])
        #
        # groups = np.array([[0,1,2,3,4],[5,6,7,8,9],[10,11,12,13,14],[15,16,17,18,19],[20,21,22,23,24]])

        n_samples, n_features = X.shape
        y = np.atleast_1d(y)
        max_grouped_features = max([len(groups[i]) for i in range(len(groups))])
        min_samples_leaf = 1
        min_weight_leaf = 0
        random_state = check_random_state(2457)

        if y.ndim == 1:
            y = np.reshape(y, (-1, 1))

        n_outputs = y.shape[1]

        y = np.copy(y)

        classes = []
        n_classes = []

        y_encoded = np.zeros(y.shape, dtype=np.float64)
        for k in range(n_outputs):
            classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
            classes.append(classes_k)
            n_classes.append(classes_k.shape[0])

        y = y_encoded

        n_classes = np.array(n_classes, dtype=np.intp)

        criterion = CARTGVGini(n_outputs, n_classes)

        splitter = BestCARTGVSplitter(criterion, max_grouped_features, len(groups),
                                         min_samples_leaf, min_weight_leaf,
                                         random_state)

        sample_weight = None
        splitter.test_init(X.to_numpy(dtype=np.float32), y, sample_weight, groups) #X.to_numpy(dtype=np.float32)

        start = 0
        end = n_samples
        weighted_n_node_samples = 0
        splitter.test_node_reset(start, end, weighted_n_node_samples)

        Xf = splitter.test_group_sample(groups[0], len(groups[0]), start, end)
        splitter.test_reset_scikit_learn_instances(y, len(groups[0]))
        splitter.test_splitting_tree_construction(Xf, y)
        splitter.test_get_splitting_tree_leaves_samples_and_pos()

    def test_switch_best_splitting_tree_BestCARTGVSplitter_v2(self):

        df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)

        train = df.loc[df['Type'] == 'train']

        X = train.iloc[:, 2:]

        y = train['Y']

        g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
        g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
        g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
        g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
        g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]

        groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])

        # X = np.array([[-0.962564615251298,-0.0818379297761482,-0.257129359665299,-1.20057124658537,-1.67321037673198,-0.850857878613548,-1.12636943482486,0.264691871869928,0.823490524418768,-0.289267055667413,0.375612134943435,0.689033636785644,-0.0755870733096488,-0.253686040025422,-0.767686310824219,-0.47706960213735,0.619681515116366,-0.718706304417254,-0.625998377401577,0.595352830214443,-0.826055466109155,0.841770278364141,0.525998122722698,-0.305537695526707,-0.551540574269715],
        #               [-0.0170226173861495,-0.575187308059669,-0.0550716676440694,-0.596082039595892,-0.153767849941737,-0.152659395126548,0.103284766044348,0.945962098961183,0.11395628892521,-1.0314335555107,-0.24180964927081,-0.225116148572662,1.75090409682049,0.276212128428595,-0.226985192750251,-0.688321496802469,0.721869146316049,-0.0427129520106458,1.71093452174155,0.440414655312213,-0.219061974136534,0.370516601227188,-0.579953711046926,-2.4756697600574,-2.09969534371281],
        #               [0.859846852829686,-0.196768997920202,-0.665097766775893,1.49845086392502,0.712519776986412,0.63382801135412,0.338132006534241,-1.17912479597116,0.337710921150664,-0.404533729530606,0.984579714687047,-1.16236566382262,-0.786198019602607,-0.753822112046281,-0.811264249392465,-0.594151853267325,-0.322916128201519,-1.2934117213506,0.531732629482942,-1.6136606736686,-1.27887838930757,0.678437793765498,-1.19080597429513,1.11533360829611,-0.340409112584892],
        #               [-1.46244895844162,0.508777691805245,-0.42599215315616,-0.570342024814983,-1.13004768682085,1.12406519881936,0.251809560422478,-2.06632443310484,-1.23862336004496,1.6527814698557,0.336827946772908,-0.233201791535758,0.590072797080428,1.7453946472635,1.02016573606479,-0.813457453508146,-0.0745696971758758,2.89463767013771,0.158622453385045,-1.70880561223817,0.132671092412739,-0.479946273307748,0.11444508132886,1.40287375218729,-0.344499428025485],
        #               [-0.383681631574503,1.19713456197882,-0.302078922002226,-0.544313316070517,1.11301409047452,0.0643648126207925,0.623795834834719,0.288528481567621,-0.618352387217919,-0.180420032776369,-0.974252399377197,-0.78154085269986,0.673878430962106,-0.14493184535421,-1.58840476437875,-0.89040398934659,-0.464336091106138,-0.804400496705168,0.542582301058101,-0.213424538311193,-0.925675256270349,0.306707969484467,0.378645850648093,0.220134583700443,-0.0925601673405935]
        #               ],dtype=np.float32)
        #
        # y = np.array([[0],[1],[0],[1],[1]])
        #
        # groups = np.array([[0,1,2,3,4],[5,6,7,8,9],[10,11,12,13,14],[15,16,17,18,19],[20,21,22,23,24]])

        n_samples, n_features = X.shape
        y = np.atleast_1d(y)
        max_grouped_features = max([len(groups[i]) for i in range(len(groups))])
        min_samples_leaf = 1
        min_weight_leaf = 0
        random_state = check_random_state(2457)

        if y.ndim == 1:
            y = np.reshape(y, (-1, 1))

        n_outputs = y.shape[1]

        y = np.copy(y)

        classes = []
        n_classes = []

        y_encoded = np.zeros(y.shape, dtype=np.float64)
        for k in range(n_outputs):
            classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
            classes.append(classes_k)
            n_classes.append(classes_k.shape[0])

        y = y_encoded

        n_classes = np.array(n_classes, dtype=np.intp)

        criterion = CARTGVGini(n_outputs, n_classes)

        splitter = BestCARTGVSplitter(criterion, max_grouped_features, len(groups),
                                         min_samples_leaf, min_weight_leaf,
                                         random_state)

        sample_weight = None
        splitter.test_init(X.to_numpy(dtype=np.float32), y, sample_weight, groups) #X.to_numpy(dtype=np.float32)

        start = 0
        end = n_samples
        weighted_n_node_samples = 0
        splitter.test_node_reset(start, end, weighted_n_node_samples)

        Xf = splitter.test_group_sample(groups[0], len(groups[0]), start, end)
        splitter.test_reset_scikit_learn_instances(y, len(groups[0]))
        splitter.test_splitting_tree_construction(Xf, y)
        splitter.test_switch_best_splitting_tree()

    def test_node_split_BestCARTGVSplitter_v2(self):

        # df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)
        #
        # train = df.loc[df['Type'] == 'train']
        #
        # X = train.iloc[:, 2:]
        #
        # y = train['Y']
        #
        # g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
        # g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
        # g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
        # g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
        # g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]
        #
        # groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])

        X = np.array([[-0.962564615251298,-0.0818379297761482,-0.257129359665299,-1.20057124658537,-1.67321037673198,-0.850857878613548,-1.12636943482486,0.264691871869928,0.823490524418768,-0.289267055667413,0.375612134943435,0.689033636785644,-0.0755870733096488,-0.253686040025422,-0.767686310824219,-0.47706960213735,0.619681515116366,-0.718706304417254,-0.625998377401577,0.595352830214443,-0.826055466109155,0.841770278364141,0.525998122722698,-0.305537695526707,-0.551540574269715],
                      [-0.0170226173861495,-0.575187308059669,-0.0550716676440694,-0.596082039595892,-0.153767849941737,-0.152659395126548,0.103284766044348,0.945962098961183,0.11395628892521,-1.0314335555107,-0.24180964927081,-0.225116148572662,1.75090409682049,0.276212128428595,-0.226985192750251,-0.688321496802469,0.721869146316049,-0.0427129520106458,1.71093452174155,0.440414655312213,-0.219061974136534,0.370516601227188,-0.579953711046926,-2.4756697600574,-2.09969534371281],
                      [0.859846852829686,-0.196768997920202,-0.665097766775893,1.49845086392502,0.712519776986412,0.63382801135412,0.338132006534241,-1.17912479597116,0.337710921150664,-0.404533729530606,0.984579714687047,-1.16236566382262,-0.786198019602607,-0.753822112046281,-0.811264249392465,-0.594151853267325,-0.322916128201519,-1.2934117213506,0.531732629482942,-1.6136606736686,-1.27887838930757,0.678437793765498,-1.19080597429513,1.11533360829611,-0.340409112584892],
                      [-1.46244895844162,0.508777691805245,-0.42599215315616,-0.570342024814983,-1.13004768682085,1.12406519881936,0.251809560422478,-2.06632443310484,-1.23862336004496,1.6527814698557,0.336827946772908,-0.233201791535758,0.590072797080428,1.7453946472635,1.02016573606479,-0.813457453508146,-0.0745696971758758,2.89463767013771,0.158622453385045,-1.70880561223817,0.132671092412739,-0.479946273307748,0.11444508132886,1.40287375218729,-0.344499428025485],
                      [-0.383681631574503,1.19713456197882,-0.302078922002226,-0.544313316070517,1.11301409047452,0.0643648126207925,0.623795834834719,0.288528481567621,-0.618352387217919,-0.180420032776369,-0.974252399377197,-0.78154085269986,0.673878430962106,-0.14493184535421,-1.58840476437875,-0.89040398934659,-0.464336091106138,-0.804400496705168,0.542582301058101,-0.213424538311193,-0.925675256270349,0.306707969484467,0.378645850648093,0.220134583700443,-0.0925601673405935]
                      ],dtype=np.float32)

        y = np.array([[0],[1],[0],[1],[1]])

        groups = np.array([[0,1,2,3,4],[5,6,7,8,9],[10,11,12,13,14],[15,16,17,18,19],[20,21,22,23,24]])

        n_samples, n_features = X.shape
        y = np.atleast_1d(y)
        max_grouped_features = max([len(groups[i]) for i in range(len(groups))])
        min_samples_leaf = 1
        min_weight_leaf = 0
        random_state = check_random_state(2457)

        if y.ndim == 1:
            y = np.reshape(y, (-1, 1))

        n_outputs = y.shape[1]

        y = np.copy(y)

        classes = []
        n_classes = []

        y_encoded = np.zeros(y.shape, dtype=np.float64)
        for k in range(n_outputs):
            classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
            classes.append(classes_k)
            n_classes.append(classes_k.shape[0])

        y = y_encoded

        n_classes = np.array(n_classes, dtype=np.intp)

        criterion = CARTGVGini(n_outputs, n_classes)

        splitter = BestCARTGVSplitter(criterion, max_grouped_features, len(groups),
                                         min_samples_leaf, min_weight_leaf,
                                         random_state)

        sample_weight = None
        splitter.test_init(X, y, sample_weight, groups)  # X.to_numpy(dtype=np.float32)

        start = 0
        end = n_samples
        weighted_n_node_samples = 0
        splitter.test_node_reset(start, end, weighted_n_node_samples)

        splitter.test_node_split()

#     def test_init(self):
#
#         df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)
#
#         train = df.loc[df['Type'] == 'train']
#
#         X = train.iloc[:, 2:]
#
#         y = train['Y']
#
#         g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
#         g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
#         g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
#         g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
#         g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]
#
#         groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])
#
#         n_samples, n_features = X.shape
#         n_grouped_features = 2
#         y = np.atleast_1d(y)
#         max_grouped_features = max([len(groups[i]) for i in range(len(groups))])
#         min_samples_leaf = 1
#         min_samples_split = 2
#         min_weight_leaf = 0  # (0.25 * n_samples)
#         random_state = check_random_state(2457)
#         max_depth = 3
#         mgroup = 1
#         mvar = 10
#         min_impurity_decrease = 0.1
#         min_impurity_split = 0.0
#
#         if y.ndim == 1:
#             y = np.reshape(y, (-1, 1))
#
#         n_outputs = y.shape[1]
#
#         y = np.copy(y)
#
#         classes = []
#         n_classes = []
#
#         y_encoded = np.zeros(y.shape, dtype=np.float64)
#         for k in range(n_outputs):
#             classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
#             classes.append(classes_k)
#             n_classes.append(classes_k.shape[0])
#
#         y = y_encoded
#
#         n_classes = np.array(n_classes, dtype=np.intp)
#
#         criterion = CARTGVGini(n_outputs, n_classes)
#
#         splitter = CARTGVSplitter_v2(criterion, max_grouped_features, len(groups),
#                                   min_samples_leaf, min_weight_leaf,
#                                   random_state)
#
#         sample_weight = None
#         # res = splitter.test_init(X, y, sample_weight, groups)
#         # self.assertEqual(res, 0)
#         # self.assertIsNotNone(splitter.splitting_tree_builder)
#         # self.assertIsNotNone(splitter.splitting_tree)
#         # self.assertEqual(splitter.n_groups, 5)
#         # self.assertTrue((np.asarray(splitter.len_groups) == [5, 5, 5, 5, 5]).all())
#         # self.assertTrue(X.all().all() == splitter.X.all().all())
#         # self.assertTrue(y.all() == np.asarray(splitter.y).all())
#
#     def test_node_reset(self):
#
#         df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)
#
#         train = df.loc[df['Type'] == 'train']
#
#         X = train.iloc[:, 2:]
#
#         y = train['Y']
#
#         g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
#         g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
#         g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
#         g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
#         g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]
#
#         groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])
#
#         n_samples, n_features = X.shape
#         n_grouped_features = 2
#         y = np.atleast_1d(y)
#         max_grouped_features = max([len(groups[i]) for i in range(len(groups))])
#         min_samples_leaf = 1
#         min_samples_split = 2
#         min_weight_leaf = 0  # (0.25 * n_samples)
#         random_state = check_random_state(2457)
#         max_depth = 3
#         mgroup = 1
#         mvar = 10
#         min_impurity_decrease = 0.1
#         min_impurity_split = 0.0
#
#         if y.ndim == 1:
#             y = np.reshape(y, (-1, 1))
#
#         n_outputs = y.shape[1]
#
#         y = np.copy(y)
#
#         classes = []
#         n_classes = []
#
#         y_encoded = np.zeros(y.shape, dtype=np.float64)
#         for k in range(n_outputs):
#             classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
#             classes.append(classes_k)
#             n_classes.append(classes_k.shape[0])
#
#         y = y_encoded
#
#         n_classes = np.array(n_classes, dtype=np.intp)
#
#         criterion = CARTGVGini(n_outputs, n_classes)
#
#         splitter = CARTGVSplitter_v2(criterion, max_grouped_features, len(groups),
#                                   min_samples_leaf, min_weight_leaf,
#                                   random_state)
#
#         sample_weight = None
#         # splitter.test_init(X, y, sample_weight, groups)
#         #
#         # start = 0
#         # end = n_samples - 1
#         # weighted_n_node_samples = 0
#         # res = splitter.test_node_reset(start, end, weighted_n_node_samples)
#         # self.assertEqual(res, 0)
#         # self.assertEqual(splitter.start, start)
#         # self.assertEqual(splitter.end, end)
#         # self.assertIsNotNone(splitter.criterion)
#
#     def test_node_split(self):
#         df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)
#
#         train = df.loc[df['Type'] == 'train']
#
#         X = train.iloc[:, 2:]
#
#         y = train['Y']
#
#         g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
#         g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
#         g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
#         g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
#         g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]
#
#         # groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])
#         groups = np.array([g1_idx, g1_idx])
#         # groups = np.array([[g1_idx[0]],[g1_idx[0]]])
#         # groups = np.array([g1_idx])
#         n_samples, n_features = X.shape
#         n_grouped_features = 2
#         y = np.atleast_1d(y)
#         max_grouped_features = max([len(groups[i]) for i in range(len(groups))])
#         min_samples_leaf = 1
#         min_samples_split = 2
#         min_weight_leaf = 0 #(0.25 * n_samples)
#         random_state = check_random_state(2457)
#         max_depth = 3
#         mgroup = 1
#         mvar = 10
#         min_impurity_decrease = 0.1
#         min_impurity_split = 0.0
#
#         if y.ndim == 1:
#             y = np.reshape(y, (-1, 1))
#
#         n_outputs = y.shape[1]
#
#         y = np.copy(y)
#
#         classes = []
#         n_classes = []
#
#         y_encoded = np.zeros(y.shape, dtype=np.float64)
#         for k in range(n_outputs):
#             classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
#             classes.append(classes_k)
#             n_classes.append(classes_k.shape[0])
#
#         y = y_encoded
#
#         n_classes = np.array(n_classes, dtype=np.intp)
#
#         criterion = CARTGVGini(n_outputs, n_classes)
#
#         splitter = CARTGVSplitter_v2(criterion, max_grouped_features, len(groups),
#                                   min_samples_leaf, min_weight_leaf,
#                                   random_state)
#
#         sample_weight = None
#         X, y, sample_weight = self._check_input(np.array(X), y, sample_weight)
#         # splitter.test_init(X, y, sample_weight, groups)
#
#         start = 0
#         end = n_samples
#         weighted_n_node_samples = 0
#         # splitter.test_node_reset(start, end, weighted_n_node_samples)
#
#         # splitter.test_node_split(np.inf, 0)
#
#     def test_one_split(self):
#         df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)
#
#         train = df.loc[df['Type'] == 'train']
#
#         X = train.iloc[:, 2:]
#
#         y = train['Y']
#
#         g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
#         g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
#         g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
#         g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
#         g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]
#
#         groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])
#
#         n_samples, n_features = X.shape
#         n_grouped_features = 2
#         y = np.atleast_1d(y)
#         max_grouped_features = max([len(groups[i]) for i in range(len(groups))])
#         max_features = len(groups[0])
#         min_samples_leaf = 1
#         min_samples_split = 2
#         min_weight_leaf = 0
#         random_state = check_random_state(2457)
#         max_depth = 3
#         mgroup = 1
#         mvar = 10
#         min_impurity_decrease = 0.1
#         min_impurity_split = 0.0
#
#         if y.ndim == 1:
#             y = np.reshape(y, (-1, 1))
#
#         n_outputs = y.shape[1]
#
#         y = np.copy(y)
#
#         classes = []
#         n_classes = []
#
#         y_encoded = np.zeros(y.shape, dtype=np.float64)
#         for k in range(n_outputs):
#             classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
#             classes.append(classes_k)
#             n_classes.append(classes_k.shape[0])
#
#         y = y_encoded
#
#         n_classes = np.array(n_classes, dtype=np.intp)
#
#         criterion = CARTGVGini(n_outputs, n_classes)
#
#         splitter = CARTGVSplitter_v2(criterion, max_grouped_features, len(groups),
#                                   min_samples_leaf, min_weight_leaf,
#                                   random_state)
#
#         clf = DecisionTreeClassifier(max_depth=max_depth, random_state=random_state, max_features=len(groups[0]),
#                                      max_leaf_nodes=X.shape[0])
#         tree = clf.fit(X.iloc[:, groups[0]], y)
#         fig, ax = plt.subplots(1, 2, figsize=(16, 9))
#         # plot_tree(tree, ax=ax[0])
#         # plt.show()
#
#         sample_weight = None
#         X, y, sample_weight = self._check_input(np.array(X.iloc[:, groups[0]]), y, sample_weight)
#         # splitter.test_init(X, y, sample_weight, groups)
#         #
#         # start = 0
#         # end = n_samples
#         # weighted_n_node_samples = 0
#         # splitter.test_node_reset(start, end, weighted_n_node_samples)
#         #
#         # splitter.test_one_split(np.inf, 0)
#         #
#         # self.assertIsNotNone(splitter.splitting_tree)
#         # self.assertIsNotNone(splitter.criterion)
#         # self.assertIsNotNone(splitter.splitting_tree_builder)
#         # self.assertTrue(splitter.splitting_tree.node_count > 1)
#
#         # clf2 = DecisionTreeClassifier(max_depth=max_depth, random_state=random_state, max_features=len(groups[0]),
#         #                               max_leaf_nodes=X.shape[0])
#         # clf2.tree_ = splitter.splitting_tree
#         # plot_tree(clf2, ax=ax[1])
#         # plt.title("current")
#         # plt.show()
#
#         # self.assertEqual(splitter.splitting_tree.n_features, clf.tree_.n_features)
#         # self.assertEqual(splitter.splitting_tree.n_classes, clf.tree_.n_classes)
#         # self.assertEqual(splitter.splitting_tree.n_outputs, clf.tree_.n_outputs)
#         # self.assertEqual(splitter.splitting_tree.max_n_classes, clf.tree_.max_n_classes)
#         # self.assertEqual(splitter.splitting_tree.max_depth, clf.tree_.max_depth)
#         # self.assertEqual(splitter.splitting_tree.node_count, clf.tree_.node_count)
#         # self.assertEqual(splitter.splitting_tree.n_leaves, clf.tree_.n_leaves)
#         # self.assertEqual(splitter.splitting_tree.value.all(), clf.tree_.value.all())
#
#     def test_n_split(self):
#         df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)
#
#         train = df.loc[df['Type'] == 'train']
#
#         X = train.iloc[:, 2:]
#
#         y = train['Y']
#
#         g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
#         g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
#         g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
#         g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
#         g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]
#
#         groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])
#
#         n_samples, n_features = X.shape
#         n_grouped_features = 2
#         y = np.atleast_1d(y)
#         max_grouped_features = max([len(groups[i]) for i in range(len(groups))])
#         max_features = len(groups[0])
#         min_samples_leaf = 1
#         min_samples_split = 2
#         min_weight_leaf = 0
#         random_state = check_random_state(2457)
#         max_depth = 3
#         mgroup = 1
#         mvar = 10
#         min_impurity_decrease = 0.1
#         min_impurity_split = 0.0
#
#         if y.ndim == 1:
#             y = np.reshape(y, (-1, 1))
#
#         n_outputs = y.shape[1]
#
#         y = np.copy(y)
#
#         classes = []
#         n_classes = []
#
#         y_encoded = np.zeros(y.shape, dtype=np.float64)
#         for k in range(n_outputs):
#             classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
#             classes.append(classes_k)
#             n_classes.append(classes_k.shape[0])
#
#         y = y_encoded
#
#         n_classes = np.array(n_classes, dtype=np.intp)
#
#         criterion = CARTGVGini(n_outputs, n_classes)
#
#         splitter = CARTGVSplitter_v2(criterion, max_grouped_features, len(groups),
#                                   min_samples_leaf, min_weight_leaf,
#                                   random_state)
#
#         clf = DecisionTreeClassifier(max_depth=max_depth, random_state=random_state, max_features=len(groups[0]),
#                                      max_leaf_nodes=X.shape[0])
#         tree = clf.fit(X.iloc[:, groups[0]], y)
#         fig, ax = plt.subplots(1, 2, figsize=(16, 9))
#         # plot_tree(tree, ax=ax[0])
#         # plt.show()
#
#         sample_weight = None
#         X, y, sample_weight = self._check_input(np.array(X.iloc[:, groups[0]]), y, sample_weight)
#         # splitter.test_init(X, y, sample_weight, groups)
#         #
#         # start = 0
#         # end = n_samples
#         # weighted_n_node_samples = 0
#         # splitter.test_node_reset(start, end, weighted_n_node_samples)
#         #
#         # splitter.test_n_split(np.inf, 0, 4, 4 - 1)
#         #
#         # self.assertIsNotNone(splitter.splitting_tree)
#         # self.assertIsNotNone(splitter.criterion)
#         # self.assertIsNotNone(splitter.splitting_tree_builder)
#         # self.assertTrue(splitter.splitting_tree.node_count > 1)
#
#         # clf2 = DecisionTreeClassifier(max_depth=max_depth, random_state=random_state, max_features=len(groups[0]),
#         #                               max_leaf_nodes=X.shape[0])
#         # clf2.tree_ = splitter.splitting_tree
#         # plot_tree(clf2, ax=ax[1])
#         # plt.title("current")
#         # plt.show()
#
#         # self.assertEqual(splitter.splitting_tree.n_features, clf.tree_.n_features)
#         # self.assertEqual(splitter.splitting_tree.n_classes, clf.tree_.n_classes)
#         # self.assertEqual(splitter.splitting_tree.n_outputs, clf.tree_.n_outputs)
#         # self.assertEqual(splitter.splitting_tree.max_n_classes, clf.tree_.max_n_classes)
#         # self.assertEqual(splitter.splitting_tree.max_depth, clf.tree_.max_depth)
#         # self.assertEqual(splitter.splitting_tree.node_count, clf.tree_.node_count)
#         # self.assertEqual(splitter.splitting_tree.n_leaves, clf.tree_.n_leaves)
#         # self.assertEqual(splitter.splitting_tree.value.all(), clf.tree_.value.all())
#
#     def test_splitting_tree_serialization(self):
#
#         df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)
#
#         train = df.loc[df['Type'] == 'train']
#
#         X = train.iloc[:, 2:]
#
#         y = train['Y']
#
#         g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
#         g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
#         g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
#         g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
#         g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]
#
#         groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])
#         y = np.atleast_1d(y)
#
#         random_state = check_random_state(2457)
#         max_depth = 3
#
#         if y.ndim == 1:
#             y = np.reshape(y, (-1, 1))
#
#         n_outputs = y.shape[1]
#
#         y = np.copy(y)
#
#         classes = []
#         n_classes = []
#
#         y_encoded = np.zeros(y.shape, dtype=np.float64)
#         for k in range(n_outputs):
#             classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
#             classes.append(classes_k)
#             n_classes.append(classes_k.shape[0])
#
#         y = y_encoded
#
#         clf = DecisionTreeClassifier(max_depth=max_depth, random_state=random_state, max_features=len(groups[0]),
#                                      max_leaf_nodes=X.shape[0])
#         tree = clf.fit(X.iloc[:, groups[0]], y)
#
#         splitting_tree_serialized = pickle.dumps(clf.tree_)
#         splitting_tree_unserialized = pickle.loads(splitting_tree_serialized)
#
#         self.assertEqual(splitting_tree_unserialized.n_features, clf.tree_.n_features)
#         self.assertEqual(splitting_tree_unserialized.n_classes, clf.tree_.n_classes)
#         self.assertEqual(splitting_tree_unserialized.n_outputs, clf.tree_.n_outputs)
#         self.assertEqual(splitting_tree_unserialized.max_n_classes, clf.tree_.max_n_classes)
#         self.assertEqual(splitting_tree_unserialized.max_depth, clf.tree_.max_depth)
#         self.assertEqual(splitting_tree_unserialized.node_count, clf.tree_.node_count)
#         self.assertEqual(splitting_tree_unserialized.n_leaves, clf.tree_.n_leaves)
#         self.assertEqual(splitting_tree_unserialized.value.all(), clf.tree_.value.all())
#
#     def test_splitting_tree_into_struct(self):
#         df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)
#
#         train = df.loc[df['Type'] == 'train']
#
#         X = train.iloc[:, 2:]
#
#         y = train['Y']
#
#         g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
#         g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
#         g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
#         g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
#         g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]
#
#         groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])
#
#         n_samples, n_features = X.shape
#         n_grouped_features = 2
#         y = np.atleast_1d(y)
#         max_grouped_features = max([len(groups[i]) for i in range(len(groups))])
#         max_features = len(groups[0])
#         min_samples_leaf = 1
#         min_samples_split = 2
#         min_weight_leaf = 0
#         random_state = check_random_state(2457)
#         max_depth = 3
#         mgroup = 1
#         mvar = 10
#         min_impurity_decrease = 0.1
#         min_impurity_split = 0.0
#
#         if y.ndim == 1:
#             y = np.reshape(y, (-1, 1))
#
#         n_outputs = y.shape[1]
#
#         y = np.copy(y)
#
#         classes = []
#         n_classes = []
#
#         y_encoded = np.zeros(y.shape, dtype=np.float64)
#         for k in range(n_outputs):
#             classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
#             classes.append(classes_k)
#             n_classes.append(classes_k.shape[0])
#
#         y = y_encoded
#
#         n_classes = np.array(n_classes, dtype=np.intp)
#
#         criterion = CARTGVGini(n_outputs, n_classes)
#
#         splitter = CARTGVSplitter_v2(criterion, max_grouped_features, len(groups),
#                                   min_samples_leaf, min_weight_leaf,
#                                   random_state)
#
#         clf = DecisionTreeClassifier(max_depth=max_depth, random_state=random_state, max_features=len(groups[0]),
#                                      max_leaf_nodes=X.shape[0])
#         tree = clf.fit(X.iloc[:, groups[0]], y)
#
#         # splitting_tree = splitter.test_splitting_tree_into_struct(clf.tree_)
#         #
#         # splitting_tree_unserialized = pickle.loads(splitting_tree)
#         #
#         # self.assertEqual(splitting_tree_unserialized.n_features, clf.tree_.n_features)
#         # self.assertEqual(splitting_tree_unserialized.n_classes, clf.tree_.n_classes)
#         # self.assertEqual(splitting_tree_unserialized.n_outputs, clf.tree_.n_outputs)
#         # self.assertEqual(splitting_tree_unserialized.max_n_classes, clf.tree_.max_n_classes)
#         # self.assertEqual(splitting_tree_unserialized.max_depth, clf.tree_.max_depth)
#         # self.assertEqual(splitting_tree_unserialized.node_count, clf.tree_.node_count)
#         # self.assertEqual(splitting_tree_unserialized.n_leaves, clf.tree_.n_leaves)
#         # self.assertEqual(splitting_tree_unserialized.value.all(), clf.tree_.value.all())
#
#     def test_splitting_tree_construction(self):
#         df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)
#
#         train = df.loc[df['Type'] == 'train']
#
#         X = train.iloc[:, 2:]
#
#         y = train['Y']
#
#         y = y.to_numpy()
#         y = np.ndarray((y.shape[0], 1), buffer=y, dtype=np.intp)
#
#         g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
#         g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
#         g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
#         g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
#         g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]
#
#         groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])
#
#         f_j = 0
#
#         n_outputs = y.shape[1]
#         n_features = X.shape[1]
#         classes = []
#         n_classes = []
#
#         for k in range(n_outputs):
#             classes_k = np.unique(y[:, k])
#             classes.append(classes_k)
#             n_classes.append(classes_k.shape[0])
#
#         n_classes = np.array(n_classes, dtype=np.intp)
#
#         # Reset the splitting tree for the next loop iteration
#         splitting_tree = Tree(n_features, n_classes, n_outputs)
#
#         max_features = len(groups[f_j])
#         max_leaf_nodes = X.shape[0]
#         min_samples_leaf = 1
#         min_samples_split = 2
#         min_weight_leaf = 0.0
#         max_depth = 3
#         min_impurity_decrease = 0
#         min_impurity_split = 0
#         random_state = check_random_state(2547)
#         max_grouped_features = max([len(groups[i]) for i in range(len(groups))])
#
#         # Create the Criterion, Splitter et TreeBuilder for the splitting tree
#         criterion = Gini(n_outputs, n_classes)
#         splitter = BestSplitter(criterion, max_features, min_samples_leaf, min_weight_leaf, random_state)
#
#         splitting_tree_builder = DepthFirstTreeBuilder(splitter, min_samples_split,
#                                                        min_samples_leaf,
#                                                        min_weight_leaf,
#                                                        max_depth,
#                                                        min_impurity_decrease,
#                                                        min_impurity_split)
#
#         cartgvcriterion = CARTGVGini(n_outputs, n_classes)
#
#         cartgvsplitter = CARTGVSplitter_v2(cartgvcriterion, max_grouped_features, len(groups),
#                                   min_samples_leaf, min_weight_leaf,
#                                   random_state)
#
#         sample_weight = None
#         X, y, sample_weight = self._check_input(np.array(X.iloc[:, groups[0]]), y, sample_weight)
#
#         # cartgvsplitter.test_init(X,y,sample_weight,groups)
#         #
#         # cartgvsplitter.splitting_tree = splitting_tree
#         # cartgvsplitter.splitting_tree_builder = splitting_tree_builder
#         #
#         # group = groups[0]
#         # len_groups = np.array([len(group) for group in groups])
#         # len_group = len(group)
#         # start = 0
#         # end = X.shape[0]
#         #
#         # Xf = cartgvsplitter.group_sample(group, len_group, start, end)
#         #
#         # clf = DecisionTreeClassifier(max_depth=max_depth, random_state=random_state, max_features=len(groups[0]),
#         #                                  max_leaf_nodes=X.shape[0])
#
#         fig, ax = plt.subplots(2, 4, figsize=(16, 9))
#
#         clf = DecisionTreeClassifier(max_depth=max_depth, random_state=random_state, max_features=len(groups[0]),
#                                      max_leaf_nodes=X.shape[0])
#         tree = clf.fit(X, y)
#         # plot_tree(tree, ax=ax[1][3])
#         # plt.title("Reference")
#
#         # for i in range(7):
#             # print("################# Splitting tree Construction " + str(i) + " ####################")
#             # cartgvsplitter.splitting_tree_construction(Xf, y)
#             # clf.tree_ = cartgvsplitter.splitting_tree
#             # plot_tree(clf, ax=ax[i//4][i%4])
#             # if(i%2 == 0):
#             #     cartgvsplitter.reset_scikit_learn_instances(y, len_groups)
#         # plt.show()
#
#     # def test_best_node_split(self):
#     #     df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)
#     #
#     #     train = df.loc[df['Type'] == 'train']
#     #
#     #     X = train.iloc[:, 2:]
#     #
#     #     y = train['Y']
#     #
#     #     g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
#     #     g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
#     #     g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
#     #     g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
#     #     g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]
#     #
#     #     groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])
#     #
#     #     n_samples, n_features = X.shape
#     #     n_grouped_features = 2
#     #     y = np.atleast_1d(y)
#     #     max_grouped_features = max([len(groups[i]) for i in range(len(groups))])
#     #     min_samples_leaf = 1
#     #     min_samples_split = 2
#     #     min_weight_leaf = 0.0
#     #     random_state = check_random_state(2457)
#     #     max_depth = 3
#     #     mgroup = 1
#     #     mvar = 10
#     #     min_impurity_decrease = 0.1
#     #     min_impurity_split = 0.0
#     #
#     #     if y.ndim == 1:
#     #         y = np.reshape(y, (-1, 1))
#     #
#     #     n_outputs = y.shape[1]
#     #
#     #     y = np.copy(y)
#     #
#     #     classes = []
#     #     n_classes = []
#     #
#     #     y_encoded = np.zeros(y.shape, dtype=np.float64)
#     #     for k in range(n_outputs):
#     #         classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
#     #         classes.append(classes_k)
#     #         n_classes.append(classes_k.shape[0])
#     #
#     #     y = y_encoded
#     #
#     #     n_classes = np.array(n_classes, dtype=np.intp)
#     #
#     #     criterion = CARTGVGini(n_outputs, n_classes)
#     #
#     #     splitter = CARTGVSplitter(criterion, max_grouped_features, len(groups),
#     #                               min_samples_leaf, min_weight_leaf,
#     #                               random_state)
#     #
#     #     sample_weight = None
#     #     X, y, sample_weight = self._check_input(np.array(X), y, sample_weight)
#     #     splitter.test_init(X, y, sample_weight, groups)
#     #
#     #     start = 0
#     #     end = n_samples
#     #     weighted_n_node_samples = 0
#     #     splitter.test_node_reset(start, end, weighted_n_node_samples)
#     #
#     #     best = splitter.test_best_node_split(np.inf, 0) #tree1, tree2,
#     #
#     #     clf = DecisionTreeClassifier(max_depth=max_depth, random_state=random_state, max_features=len(groups[0]),
#     #                                  max_leaf_nodes=X.shape[0])
#     #
#     #     # tree1 = pickle.loads(tree1)
#     #     # tree2 = pickle.loads(tree2)
#     #     # best = pickle.loads(best)
#     #     # print(tree1)
#     #     # print(tree2)
#     #     print(best)
#     #
#     #     # clf.tree_ = tree1
#     #     # print("plt subplot")
#     #     # fig, ax = plt.subplots(1, 3, figsize=(16, 9))
#     #     # print("plot tree")
#     #     # plot_tree(clf, ax=ax[0])
#     #     # # plot_tree(clf)
#     #     # # plt.show()
#     #     # plt.title("current")
#     #     #
#     #     # print("tree1 done")
#     #     #
#     #     # tree2 = pickle.loads(tree2)
#     #     # clf.tree_ = tree2
#     #     # plot_tree(clf, ax=ax[1])
#     #     # # plot_tree(clf)
#     #     # # plt.show()
#     #     # plt.title("current")
#     #     #
#     #     # print("tree2 done")
#     #     #
#     #     best = pickle.loads(best)
#     #     print(best)
#     #     print(best.node_count)
#     #     clf.tree_ = best
#     #     # plot_tree(clf)
#     #     # plot_tree(clf, ax=ax[2])
#     #     # plt.title("current")
#     #     # plt.show()
#     #
#     #     print("best tree done")
#     #     return 0
#
#     def test_node_samples_construction(self):
#
#         df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)
#
#         train = df.loc[df['Type'] == 'train']
#
#         X = train.iloc[:, 2:]
#
#         samples = np.arange(X.shape[0])
#
#         g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
#         g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
#         g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
#         g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
#         g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]
#
#         groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])
#         len_groups = np.array([len(g1_idx), len(g2_idx), len(g3_idx), len(g4_idx), len(g5_idx)])
#
#         start = 0
#         end = 334
#
#         f_j = 0  # np.random.randint(0,max_grouped_features)           # Select a group at random
#
#         group = groups[f_j]
#         len_group = len_groups[f_j]
#
#         Xf = np.empty((end - start, len_group))  # Rcupre la shape correcte des donnes
#         X = X.to_numpy()
#
#         # Take the observations columns of group f_j between indexes start and end
#         for i in range(start, end):
#             for l in range(len_group):
#                 Xf[i][l] = X[samples[i], group[l]]
#
#         self.assertEqual(Xf[start][0], X[samples[start], [0]])
#         self.assertEqual(Xf[end-start-1][0], X[samples[end-start-1], [0]])
#
#
#     def test_sklearn_tree_build(self):
#
#         df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)
#
#         train = df.loc[df['Type'] == 'train']
#
#         X = train.iloc[:, 2:]
#
#         y = train['Y']
#
#         y = y.to_numpy()
#         y = np.ndarray((y.shape[0], 1), buffer=y, dtype=np.intp)
#         print(X.to_numpy().shape)
#
#         g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
#         g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
#         g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
#         g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
#         g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]
#
#         groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])
#
#         for i in range(2):
#
#             f_j = 0
#
#             n_outputs = y.shape[1]
#             n_features = X.shape[1]
#             classes = []
#             n_classes = []
#
#             for k in range(n_outputs):
#                 classes_k = np.unique(y[:,k])
#                 classes.append(classes_k)
#                 n_classes.append(classes_k.shape[0])
#
#             n_classes = np.array(n_classes, dtype=np.intp)
#
#             # Reset the splitting tree for the next loop iteration
#             splitting_tree = Tree(n_features, n_classes, n_outputs)
#
#             max_features = len(groups[f_j])
#             max_leaf_nodes = X.shape[0]
#             min_samples_leaf = 1
#             min_samples_split = 2
#             min_weight_leaf = 0.0
#             max_depth = 3
#             min_impurity_decrease = 0
#             min_impurity_split = 0
#             random_state = check_random_state(2547)
#
#             # Create the Criterion, Splitter et TreeBuilder for the splitting tree
#             criterion = Gini(n_outputs, n_classes)
#             splitter = BestSplitter(criterion, max_features, min_samples_leaf, min_weight_leaf, random_state)
#
#             splitting_tree_builder = DepthFirstTreeBuilder(splitter, min_samples_split,
#                                                                 min_samples_leaf,
#                                                                 min_weight_leaf,
#                                                                 max_depth,
#                                                                 min_impurity_decrease,
#                                                                 min_impurity_split)
#
#             splitting_tree_builder.build(splitting_tree, np.asarray(X), y, None)
#
#             clf = DecisionTreeClassifier(max_depth=max_depth, random_state=random_state, max_features=len(groups[0]),
#                                          max_leaf_nodes=X.shape[0])
#             clf.tree_ = splitting_tree
#             # plot_tree(clf)
#             # plt.show()
#
#             # Necessary loop to get the number of leaves as self.splitting_tree.n_leaves crash the program (the np.sum in the splitting_tree.n_leaves property has an error)
#             n_leaves = 0
#             for i in range(len(splitting_tree.children_left)):
#                 if splitting_tree.children_left[i] == -1 and splitting_tree.children_right[i] == -1:
#                     n_leaves += 1
#
#             n_nodes = splitting_tree.node_count
#
#             self.assertEqual(n_nodes, 13)
#             self.assertEqual(n_leaves, 7)
#
#     # def test_sklearn_builder_field(self):
#     #     df = pd.read_csv('CARTGV/data_Mael.csv', sep=";", index_col=0)
#     #
#     #     train = df.loc[df['Type'] == 'train']
#     #
#     #     X = train.iloc[:, 2:]
#     #
#     #     y = train['Y']
#     #
#     #     g1_idx = [col for col in range(len(X.columns)) if '_G1' in X.columns[col]]
#     #     g2_idx = [col for col in range(len(X.columns)) if '_G2' in X.columns[col]]
#     #     g3_idx = [col for col in range(len(X.columns)) if '_G3' in X.columns[col]]
#     #     g4_idx = [col for col in range(len(X.columns)) if '_G4' in X.columns[col]]
#     #     g5_idx = [col for col in range(len(X.columns)) if '_G5' in X.columns[col]]
#     #
#     #     groups = np.array([g1_idx, g2_idx, g3_idx, g4_idx, g5_idx])
#     #
#     #     y = np.atleast_1d(y)
#     #     max_grouped_features = max([len(groups[i]) for i in range(len(groups))])
#     #     min_samples_leaf = 1
#     #     min_weight_leaf = 0
#     #     random_state = check_random_state(2457)
#     #
#     #
#     #     if y.ndim == 1:
#     #         y = np.reshape(y, (-1, 1))
#     #
#     #     n_outputs = y.shape[1]
#     #
#     #     y = np.copy(y)
#     #
#     #     classes = []
#     #     n_classes = []
#     #
#     #     y_encoded = np.zeros(y.shape, dtype=np.float64)
#     #     for k in range(n_outputs):
#     #         classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)
#     #         classes.append(classes_k)
#     #         n_classes.append(classes_k.shape[0])
#     #
#     #     y = y_encoded
#     #
#     #     n_classes = np.array(n_classes, dtype=np.intp)
#     #
#     #     criterion = CARTGVGini(n_outputs, n_classes)
#     #
#     #     splitter = CARTGVSplitter(criterion, max_grouped_features, len(groups),
#     #                               min_samples_leaf, min_weight_leaf,
#     #                               random_state)
#     #
#     #     sample_weight = None
#     #     X, y, sample_weight = self._check_input(np.array(X), y, sample_weight)
#     #     splitter.test_init(X, y, sample_weight, groups)
#     #
#     #     start = 0
#     #     end = X.shape[0]
#     #     weighted_n_node_samples = 0
#     #     splitter.test_node_reset(start, end, weighted_n_node_samples)
#     #
#     #     splitter.test_sklearn_builder_field()
#
#     def _check_input(self, X, y, sample_weight):
#         """Check input dtype, layout and format"""
#         if issparse(X):
#             X = X.tocsc()
#             X.sort_indices()
#
#             if X.data.dtype != DTYPE:
#                 X.data = np.ascontiguousarray(X.data, dtype=DTYPE)
#
#             if X.indices.dtype != np.int32 or X.indptr.dtype != np.int32:
#                 raise ValueError("No support for np.int64 index based "
#                                  "sparse matrices")
#
#         elif X.dtype != DTYPE:
#             # since we have to copy we will make it fortran for efficiency
#             X = np.asfortranarray(X, dtype=DTYPE)
#
#         if y.dtype != DOUBLE or not y.flags.contiguous:
#             y = np.ascontiguousarray(y, dtype=DOUBLE)
#
#         if (sample_weight is not None and
#                 (sample_weight.dtype != DOUBLE or
#                  not sample_weight.flags.contiguous)):
#             sample_weight = np.asarray(sample_weight, dtype=DOUBLE,
#                                        order="C")
#
#         return X, y, sample_weight
#
#
# class CARTGVTreeTest(unittest.TestCase):

if __name__ == '__main__':
    unittest.main()
